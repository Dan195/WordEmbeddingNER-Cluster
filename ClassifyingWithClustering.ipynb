{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification tests - Testing K Nearest Neighbors, Random Forest and Support Vector Classifications using a test set of 50 documents\n",
    "## Try these 3 different models to classify with word vectors of candidates generated via word2vec \n",
    "## Try these 3 different models to classify PS-similarity measures from candidates generated via word2vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from   __future__ import division\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "from   matplotlib.colors import ListedColormap\n",
    "from   sklearn import neighbors, datasets\n",
    "import gensim, logging\n",
    "from gensim.models import FastText\n",
    "import fasttext\n",
    "\n",
    "\n",
    "from   sklearn import svm\n",
    "from   sklearn.svm import SVR\n",
    "from   sklearn.svm import SVC\n",
    "from   sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import sklearn\n",
    "import spacy\n",
    "\n",
    "from   sklearn.model_selection import train_test_split\n",
    "from   sklearn.model_selection import GridSearchCV\n",
    "from   sklearn.metrics import classification_report\n",
    "from   sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from   sklearn.manifold import TSNE\n",
    "\n",
    "from   sklearn.ensemble import RandomForestRegressor\n",
    "from   sklearn.model_selection import train_test_split, GridSearchCV, ShuffleSplit\n",
    "import scipy as sp\n",
    "import _pickle as pkl\n",
    "#import cPickle as pkl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from   sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# This log shows progress and is very useful\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "# Load spacy for candidate processing\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# Adding these into the vocabulary\n",
    "nlp.vocab[u\"diblock\"].is_stop = False\n",
    "nlp.vocab[u\"g/mol\"].is_stop   = False\n",
    "nlp.vocab[u\"kg/mol\"].is_stop  = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUND_TRUTH_INPUT = \"../ground_truth/ground_truth_list_format.txt\"\n",
    "FULL_CANDIDATES = \"../../data/polymer_ner_evaluation.csv\"\n",
    "CBOW_MODEL = \"../../models/FT_cbow.bin\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we will create a file with all of the sentences from the processed_sentence column in \n",
    "sentences table. This file will serve as the training file for the fasttext unsupervised learning algorithm,\n",
    "and the vectors will then be used for clustering and classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to db\n",
    "def connect_to_db():\n",
    "    database = \"../../db/sentences.db\"\n",
    "    conn = create_connection(database)\n",
    "    return conn\n",
    "# Connect to DB\n",
    "def create_connection(db_file):\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    " \n",
    "    return None\n",
    "\n",
    "# Get sentences\n",
    "def get_sentences_from_db(conn):\n",
    "    sentences = ''\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"select processed_sentence from sentences\") \n",
    "    rows = cur.fetchall()\n",
    "    \n",
    "    with open('processed_sentences.txt','w',encoding=\"utf-8\") as f:\n",
    "        for row in rows:\n",
    "             f.write(row[0]+'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will train the FastText algorithm on polymers.test . The polymers.test includes 150 documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = connect_to_db()\n",
    "get_sentences_from_db(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we will get the models both for the supervised vectors and unsupervised vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_model = fasttext.train_supervised('../../data/polymers.test')\n",
    "unsupervised_model = fasttext.train_unsupervised('processed_sentences.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Exploration</h1> <br><br>\n",
    "First, we will take a look at the polymers from the ground_truth file and see which ones are the most popular based\n",
    "on their frequency in the data.test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_table(\"../../data/polymers.test\",encoding=\"utf-8\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_list_from_doc(test_data):\n",
    "    \"\"\"processes dfs where original file \n",
    "    is of the form [label, sentence] \"\"\"\n",
    "    \n",
    "    sentences_to_words = []\n",
    "    \n",
    "    df = pd.DataFrame(test_data[0].str.split(\" \",1))\n",
    "    sentences = df[0].str[1].apply(lambda x: x.lstrip('b'))\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        words = sentence.split(\" \")\n",
    "        for word in words:\n",
    "            sentences_to_words.append(word)\n",
    "    \n",
    "    return sentences_to_words\n",
    "\n",
    "def get_ground_truths(gt_input):\n",
    "    with open(gt_input, 'r') as f:\n",
    "        ground_truths = f.readlines()\n",
    "        \n",
    "    return [ground_truth.strip('\\n') for ground_truth in ground_truths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truths = get_ground_truths(GROUND_TRUTH_INPUT)\n",
    "word_counts = Counter(word_list_from_doc(test))\n",
    "word_counts_sorted = {k: v for k, v in sorted(word_counts.items(), key=lambda item: item[1],reverse=True)}\n",
    "ground_truth_counts = {k: word_counts[k] for k in ground_truths}\n",
    "ground_truth_counts = {k: v for k, v in sorted(ground_truth_counts.items(), key=lambda item: item[1],reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#word_counts_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ground_truth_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above, I have the following ideas...\n",
    "1. Add a feature for has_numeric. 1 if word has numeric AND has alphabetic chars, 0 else.\n",
    "2. has_dash - This returns 1 if contains \"-\", else 0.\n",
    "3. has_parentheses - This feature value is 1 if contains \"(\" and \")\" else 0.\n",
    "4. has_slash - 1 if contains \"/\" or \"\\\" else 0.\n",
    "5. contains_poly - returns 1 if \"poly\" in lowercase string, else 0. This is most questionable feature as this info should be somewhat accounted for in similarity measure vector approach\n",
    "6. len string - Also somewhat questionable as it could double based on similarity measure used against 3 common polymers. \n",
    "\n",
    "Proposal, keep \"PS\" similarity measure as feature to hopefully help find the abbreviated polymers. Remove other 2\n",
    "as those ones might fair better with binary attributes contains_poly and has_parentheses especially if using\n",
    "a tree based classification approach.\n",
    "\n",
    "Also, on top of the English word removal, potentially add common abbreviations such as i.e. and e.g. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets candidates from a fulldocument of candidates text file\n",
    "def get_fulldoc_candidates(doc_path):\n",
    "    with open(doc_path,'r', encoding='utf-8') as f:\n",
    "        candidates = f.readlines()\n",
    "        \n",
    "    return [candidate.strip('\\n') for candidate in candidates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_testing_data(features, target):\n",
    "    # Dataset, training and testing datasets\n",
    "    X = np.asarray(features)\n",
    "    y = np.asarray(target)\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(\n",
    "        X, y, test_size=0.1, random_state=0)\n",
    "    return Xtrain, Xtest, ytrain, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metrics - I think I can do that with scikit learn\n",
    "def metrics(predicted, actual):  \n",
    "    true_pos = 0\n",
    "    false_pos = 0\n",
    "    false_neg = 0\n",
    "    true_neg = 0\n",
    "    num_pos = 0\n",
    "    num_polys = 0\n",
    "    for i in range(len(predicted)):\n",
    "        if predicted[i] == 1 and actual[i] == 1:\n",
    "            true_pos = true_pos + 1\n",
    "        elif predicted[i] == 1 and actual[i] == 0:\n",
    "            false_pos = false_pos + 1\n",
    "        elif predicted[i] == 0 and actual[i] == 0:\n",
    "            true_neg = true_neg + 1\n",
    "        elif predicted[i] == 0 and actual[i] == 1:\n",
    "            false_neg = false_neg + 1\n",
    "\n",
    "    print('    Test points:     %d' % len(predicted))\n",
    "    print('    True positives:  %d' % true_pos)\n",
    "    print('    False positive:  %d' % false_pos)\n",
    "    print('    True negatives:  %d' % true_neg)\n",
    "    print('    False negatives: %d' % false_neg)\n",
    "    if false_pos+true_pos > 0:\n",
    "        precision = true_pos/(true_pos+false_pos)\n",
    "\n",
    "        recall = true_pos/(true_pos+false_neg)\n",
    "        accuracy = (true_pos + true_neg)/(true_pos+true_neg+false_pos+false_neg)\n",
    "        f1score = 2/((1/recall)+(1/precision))\n",
    "    else: #FIXME\n",
    "        precision = 0\n",
    "        recall = 1\n",
    "        f1score = -1 #FIXME: check \n",
    "    print('    Precision:       %.3f' % precision)\n",
    "    print('    Recall:          %.3f' % recall)\n",
    "    #print \"Accuracy: \", accuracy / just to check my metrics function was correct\n",
    "    print('    F-1 score:       %.3f' %f1score)\n",
    "    #print clf.score(predicted,actual)\n",
    "    return f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if a string is a number\n",
    "def is_number(n):\n",
    "    try:\n",
    "        float(n)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# First use vectors as features\n",
    "def refine_candidate(candidate,model):\n",
    "    # Top context words in DB\n",
    "    frequent_context_words = [\"weight\",\"material\",\"system\",\"chains\",\"samples\", \"systems\",\"Tg\",\"weights\",\"comparison\",\"chromatography\",\"Mn\",\"THF\",\"toluene\",\"GPC\",\"chloroform\",\"index\",\"Column\",\"columns\",\"standards\",\"reference\",\"segments\",\"polydispersity\",\"substrate\",\"block\",\"components\",\"permeation\",\"component\",\"Mw\",\"bulk\",\"standard\",\"calibration\",\"dynamics\",\"cross-linked\",\"cells\",\"domains\",\"segment\",\"mixtures\",\"densities\",\"substrates\",\"well-defined\",\"silica\",\"SEC\",\"particles\",\"compositions\",\"surfaces\",\"linear\"]\n",
    "    \n",
    "    common_polys = ['polyethylene', 'polyurethane', 'polypropylene', 'polyester', 'PS', 'polystyrene', 'PLA', 'PI', 'PET', 'PVP', 'PEG', 'cellulose', 'PAN', 'methyl'] #These are polymers that could appear within spacy vocab\n",
    "    common_polys = [polymer.lower() for polymer in common_polys] \n",
    "\n",
    "    # Filter out junk values\n",
    "    junk_vals = []\n",
    "        \n",
    "    if (candidate in nlp.vocab) and candidate.lower() not in common_polys:\n",
    "        return \"ignore_due_to_english_word\"\n",
    "    \n",
    "    try:\n",
    "#         vocab_obj = model.get_word_vector(candidate) #model.wv.vocab[candidate]\n",
    "#         freq= vocab_obj.count\n",
    "\n",
    "        if candidate in frequent_context_words:\n",
    "            return \"ignore_due_to_context\"\n",
    "\n",
    "        junk = False\n",
    "        items = re.split(' |:|;|-',candidate)\n",
    "        for item in items:\n",
    "            #Removing items that are sentences within  parenthesis\n",
    "            if item != \"poly\" and is_number(item)==False and (\"standard\" in item or (item in nlp.vocab and item not in common_polys)):\n",
    "                junk = True\n",
    "                break\n",
    "\n",
    "        if junk is True:\n",
    "            return \"ignore_due_to_junk\"\n",
    "    except:\n",
    "        return \"ignore_due_to_not_in_model\"\n",
    "        \n",
    "    return \"acceptable_after_refinement\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define KNN, SVC, and RF models\n",
    "\n",
    "def knn(Xtrain,Xtest, ytrain, ytest):\n",
    "    # Number of neighbors 5 seems to work best\n",
    "    n_neighbors = 5\n",
    "\n",
    "    #for weights in ['uniform', 'distance']:\n",
    "    weights = 'uniform'\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)\n",
    "\n",
    "    clf.fit(Xtrain,ytrain)\n",
    "\n",
    "    y_predicted = clf.predict(Xtest)\n",
    "    f1s = metrics(y_predicted,ytest)\n",
    "    #print \"Classifier score (accuracy): \", clf.score(Xtest,ytest)\n",
    "   # return f1s\n",
    "    print(\"LEN X TRAIN {}\".format(str(len(Xtrain))))\n",
    "    print(\"LEN X TESST {}\".format(str(len(Xtest))))\n",
    "    print(\"LEN Y PREDICTED {}\".format(str(len(ytest))))\n",
    "    return {'y_predicted': y_predicted, 'f1s': f1s}\n",
    "\n",
    "\n",
    "def svc(Xtrain, Xtest, ytrain, ytest):\n",
    "    # Set the parameters by cross-validation\n",
    "    tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "    scores = ['precision', 'recall']\n",
    "    clf = GridSearchCV(SVC(), tuned_parameters, cv=5,\n",
    "                       scoring='%s_macro' % scores[1])\n",
    "    clf.fit(Xtrain, ytrain)\n",
    "    #print(clf.best_params_)\n",
    "    clf = clf.best_estimator_\n",
    "    y_pred = clf.predict(Xtest)\n",
    "    f1s = metrics(y_pred,ytest)\n",
    "   # return f1s\n",
    "    return {'y_predicted': y_pred, 'f1s': f1s}\n",
    "\n",
    "def RF(Xtrain, Xtest, ytrain, ytest):\n",
    "    param_grid = { \n",
    "        'max_features': ['auto', 'sqrt', 'log2']\n",
    "    }\n",
    "    \n",
    "    clf = RandomForestClassifier(max_depth=None, n_jobs=-1, max_features= 'sqrt' ,n_estimators=100, oob_score = True, random_state=None)\n",
    "    clf = GridSearchCV(RandomForestClassifier(n_estimators=100),\n",
    "                    param_grid=param_grid,\n",
    "                    scoring='f1',\n",
    "                    cv=10)\n",
    "    #clf = RandomForestClassifier(max_depth=None, max_features=3, random_state=None) # Change when using similarity scores\n",
    "    clf.fit(Xtrain, ytrain)\n",
    "    clf = clf.best_estimator_\n",
    "    y_predicted = clf.predict(Xtest)\n",
    "    f1s = metrics(y_predicted,ytest)\n",
    "   # return f1s\n",
    "    return {'y_predicted': y_predicted, 'f1s': f1s}\n",
    "\n",
    "\n",
    "def run_all_models(X, y, results, process_full_document_flag, refined_candidates_only_flag, use_word_vector_flag):\n",
    "    print('Running all classifiers, with %s candidates; %s; %s' % \n",
    "      ('refined' if refined_candidates_only_flag else 'unrefined',\n",
    "       'word vectors' if use_word_vector_flag else 'score vectors',\n",
    "       'full documents' if process_full_document_flag else 'classified sentences'))\n",
    "\n",
    "  #  X, y = get_word_vectors_as_feature(connection, process_full_document_flag, refined_candidates_only_flag, use_word_vector_flag)\n",
    "    \n",
    "    best_model1, max_f1_score1, predictions = run_all_classifiers(X, y)\n",
    "    key = ('fulldoc' if process_full_document_flag else 'classified_sentences') + '_' + ('refined' if refined_candidates_only_flag else 'unrefined') + '_' + ('words' if use_word_vector_flag else 'scores')\n",
    "    results[key] = [best_model1, max_f1_score1]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all classifiers on a particular type of input\n",
    "def run_all_classifiers(X,y):\n",
    "    print(\"RUNNING THEM ALL NOW LENGTH OF X, y IS {} {}\".format(str(len(X)),str(len(y))))\n",
    "    models = ['K Nearest Neighbor', 'Support Vector', 'Random Forest']\n",
    "    f1_scores = []\n",
    "    X_train, X_test, y_train, y_test = get_training_testing_data(X,y)\n",
    "    print(X_train)\n",
    "    print('K Nearest Neighbor:')\n",
    "    knn_results = knn(X_train, X_test, y_train, y_test)\n",
    "    print(knn_results)\n",
    "    knn_predictions,f1_score1 = knn_results['y_predicted'],knn_results['f1s']\n",
    "    f1_scores.append(f1_score1)\n",
    "    \n",
    "    print('Support Vector:')\n",
    "    svc_results = svc(X_train, X_test, y_train, y_test)\n",
    "    svc_predictions, f1_score2 = svc_results['y_predicted'], svc_results['f1s']\n",
    "    f1_scores.append(f1_score2)\n",
    "    \n",
    "    #print('Multi Layer Perceptron:')\n",
    "    #f1_score3 = MPC(X_train, X_test, y_train, y_test)\n",
    "    #print f1_score3\n",
    "    #f1_scores.append(f1_score3)\n",
    "    \n",
    "    print('Random Forest:')\n",
    "    rf_results = RF(X_train, X_test, y_train, y_test)\n",
    "    rf_predictions, f1_score4 = rf_results['y_predicted'],rf_results['f1s']\n",
    "    f1_scores.append(f1_score4)\n",
    "    max_f1 = max(f1_scores)\n",
    "    max_f1_index_arr = np.where(np.array(f1_scores)==max_f1)\n",
    "\n",
    "    for mf in range(len(max_f1_index_arr[0])):\n",
    "        max_f1_index = max_f1_index_arr[0][mf]\n",
    "        print ('%s achieves the best F1 score of %.3f' % (models[max_f1_index], f1_scores[max_f1_index]))\n",
    "    best_model = models[max_f1_index],f1_scores[max_f1_index]\n",
    "    \n",
    "    return(best_model, \n",
    "           max_f1,\n",
    "           {'knn_pred':knn_predictions,\n",
    "            'svc_pred':svc_predictions,\n",
    "            'rf_pred':rf_predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coords(words,model):\n",
    "    coords = []\n",
    "    for word in words:\n",
    "        try:\n",
    "            coords.append(model.wv.vocab[word])\n",
    "        except:\n",
    "            coords.append([0])\n",
    "        \n",
    "    return coords\n",
    "\n",
    "def get_similarity_scores_as_features(polymer_candidates, model, frequent_polymers):\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    # Polymers used to generate training data\n",
    "   # frequent_polymers = [\"polystyrene\",\"poly(styrene)\",\"PS\"]\n",
    "\n",
    "    features = {}\n",
    "    Xl = [] # vectors\n",
    "    yl = [] # target (is_poly=0:1?)\n",
    "    ll = [] # labels\n",
    "    \n",
    "   # similarities = {}\n",
    "    for candidate in polymer_candidates:\n",
    "        features[candidate] = []\n",
    "        candidate_vec = model.get_word_vector(candidate).reshape(1, -1)\n",
    "        \n",
    "        try:\n",
    "            for fp in frequent_polymers:\n",
    "                fp_vec = model.get_word_vector(fp).reshape(1, -1)\n",
    "                similarity_score = cosine_similarity(candidate_vec,fp_vec)#round(model.wv.similarity(candidate,fp),2)\n",
    "                features[candidate].append(similarity_score[0][0])\n",
    "\n",
    "            Xl.append(features[candidate])\n",
    "            yl.append(candidate)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "            \n",
    "    return Xl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clustering Setup ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hashes_from_list(list_):\n",
    "    \"\"\"returns dictionary with value 1 from a list. Its purpose is to be used when needing to find if \n",
    "    item is in a list repeatedly as this will get the find operation down to constant time.\"\"\"\n",
    "    return {key: 1 for key in list_}\n",
    "def create_df(candidates, model,ground_truths=None):\n",
    "    # is_{algo} columns are boolean as to whether or not they were predicted by that algorithm. \n",
    "    df = pd.DataFrame(columns=[\"candidate\",\"is_knn\",\"is_svc\",\"is_rf\",\"is_groundtruth\",\"db_scan_clus\",\"predictions\",\"is_refined\"])\n",
    "    #ground_truths_hashed = get_hashes_from_list(ground_truths)\n",
    "    \n",
    "    if isinstance(candidates,str):\n",
    "        with open(candidates,'r',encoding='utf-8') as candidates:\n",
    "            for candidate in candidates:\n",
    "                word_and_isgroundtruth = candidate.split(\"|\")\n",
    "                word = word_and_isgroundtruth[0].replace('\"','')\n",
    "                is_refined = refine_candidate(word, model)\n",
    "                is_groundtruth = int(word_and_isgroundtruth[1].replace('\"','').rstrip('\\n'))\n",
    "\n",
    "            # is_groundtruth = 1 if word in ground_truths_hash else 0\n",
    "                df = df.append({\"candidate\":word,\"is_groundtruth\":is_groundtruth,\"db_scan_clus\":None,\"supervised_coords\":[],\"unsupervised_coords\":[],\"is_refined\": is_refined},ignore_index=True)\n",
    "\n",
    "    else:\n",
    "        ground_truths_hashed = get_hashes_from_list(ground_truths)\n",
    "        for candidate in candidates:\n",
    "            is_refined = refine_candidate(candidate,model)\n",
    "            is_groundtruth = candidate in ground_truths_hashed\n",
    "            df = df.append({\"candidate\":candidate,\"is_groundtruth\":is_groundtruth,\"db_scan_clus\":None,\"supervised_coords\":[],\"unsupervised_coords\":[],\"is_refined\": is_refined},ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Experiment 1 </h1><br>\n",
    "The first experiment will be to go through the process as defined in the paper utilizing \n",
    "the terms from the 500 documents with the terms frfom the ground_truth file to see how clustering and the classifiers perform.\n",
    "This will use the cosine similaeity scores with the array [\"polystyrene\",\"poly(styrene)\",\"PS\"] as features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_exp1 = create_df(FULL_CANDIDATES, supervised_model)\n",
    "df_exp1 = df_exp1[df_exp1.is_refined==\"acceptable_after_refinement\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danlg\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "candidates = df_exp1.candidate\n",
    "supervised_coords = get_similarity_scores_as_features(candidates, supervised_model,  [\"polystyrene\",\"poly(styrene)\",\"PS\"])\n",
    "unsupervised_coords = get_similarity_scores_as_features(candidates, unsupervised_model,  [\"polystyrene\",\"poly(styrene)\",\"PS\"])\n",
    "df_exp1.supervised_model_coords = supervised_coords\n",
    "df_exp1.unsupervised_model_coords = unsupervised_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate</th>\n",
       "      <th>is_knn</th>\n",
       "      <th>is_svc</th>\n",
       "      <th>is_rf</th>\n",
       "      <th>is_groundtruth</th>\n",
       "      <th>db_scan_clus</th>\n",
       "      <th>predictions</th>\n",
       "      <th>is_refined</th>\n",
       "      <th>model_coords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DNA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acceptable_after_refinement</td>\n",
       "      <td>[-0.9956413, -0.9864065, -0.96618384]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>semidilute</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acceptable_after_refinement</td>\n",
       "      <td>[-0.9742995, -0.9674851, -0.95164067]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>well-entangled</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acceptable_after_refinement</td>\n",
       "      <td>[-0.63267654, -0.63258857, -0.60784334]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>fluids</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acceptable_after_refinement</td>\n",
       "      <td>[0.53739655, 0.52752966, 0.5192265]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>broad.23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acceptable_after_refinement</td>\n",
       "      <td>[0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1104</td>\n",
       "      <td>2 to 7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acceptable_after_refinement</td>\n",
       "      <td>[0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1105</td>\n",
       "      <td>polydimethylsiloxane</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acceptable_after_refinement</td>\n",
       "      <td>[0.9808457, 0.9674403, 0.9524896]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1106</td>\n",
       "      <td>four-armed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acceptable_after_refinement</td>\n",
       "      <td>[0.841585, 0.82723963, 0.8095096]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1107</td>\n",
       "      <td>rodlike</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acceptable_after_refinement</td>\n",
       "      <td>[-0.35197884, -0.35230455, -0.32604563]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1108</td>\n",
       "      <td>semicrystalline</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acceptable_after_refinement</td>\n",
       "      <td>[0.9917563, 0.9836085, 0.959339]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1036 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 candidate is_knn is_svc is_rf is_groundtruth db_scan_clus  \\\n",
       "0                      DNA      0      0     0              0         None   \n",
       "2               semidilute      0      0     0              0         None   \n",
       "3           well-entangled      0      0     0              0         None   \n",
       "7                   fluids      0      0     0              0         None   \n",
       "12                broad.23      0      0     0              0         None   \n",
       "...                    ...    ...    ...   ...            ...          ...   \n",
       "1104                2 to 7      0      0     0              1         None   \n",
       "1105  polydimethylsiloxane      0      0     0              1         None   \n",
       "1106            four-armed      0      0     0              1         None   \n",
       "1107               rodlike      0      0     0              1         None   \n",
       "1108       semicrystalline      0      0     0              1         None   \n",
       "\n",
       "     predictions                   is_refined  \\\n",
       "0            NaN  acceptable_after_refinement   \n",
       "2            NaN  acceptable_after_refinement   \n",
       "3            NaN  acceptable_after_refinement   \n",
       "7            NaN  acceptable_after_refinement   \n",
       "12           NaN  acceptable_after_refinement   \n",
       "...          ...                          ...   \n",
       "1104         NaN  acceptable_after_refinement   \n",
       "1105         NaN  acceptable_after_refinement   \n",
       "1106         NaN  acceptable_after_refinement   \n",
       "1107         NaN  acceptable_after_refinement   \n",
       "1108         NaN  acceptable_after_refinement   \n",
       "\n",
       "                                 model_coords  \n",
       "0       [-0.9956413, -0.9864065, -0.96618384]  \n",
       "2       [-0.9742995, -0.9674851, -0.95164067]  \n",
       "3     [-0.63267654, -0.63258857, -0.60784334]  \n",
       "7         [0.53739655, 0.52752966, 0.5192265]  \n",
       "12                            [0.0, 0.0, 0.0]  \n",
       "...                                       ...  \n",
       "1104                          [0.0, 0.0, 0.0]  \n",
       "1105        [0.9808457, 0.9674403, 0.9524896]  \n",
       "1106        [0.841585, 0.82723963, 0.8095096]  \n",
       "1107  [-0.35197884, -0.35230455, -0.32604563]  \n",
       "1108         [0.9917563, 0.9836085, 0.959339]  \n",
       "\n",
       "[1036 rows x 9 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_from_df(series_col):\n",
    "    arr = []\n",
    "    for coords in series_col:\n",
    "        arr.append([float(coord) for coord in coords])\n",
    "        \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read more about the algorithms...\n",
    "https://scikit-learn.org/stable/modules/clustering.html#optics\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.OPTICS.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN, AgglomerativeClustering, OPTICS, KMeans\n",
    "\n",
    "def run_dbscan(X):\n",
    "    clustering = DBSCAN().fit(X)\n",
    "    return clustering.labels_\n",
    "    \n",
    "def run_kmeans(X,params):\n",
    "    clustering = KMeans(**params).fit(X)\n",
    "    return clustering.labels_\n",
    "\n",
    "def run_optics(X,args):\n",
    "    optics = OPTICS(**args).fit(X)\n",
    "    return optics.labels_\n",
    "\n",
    "def run_agg_clustering(X,args):\n",
    "    clustering = AgglomerativeClustering(**args).fit(X)\n",
    "    return clustering.labels_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_cluster_homogeneity(labels,words,ground_truths_hash):\n",
    "    cluster_frequency = Counter(labels)\n",
    "    ground_truths_in_clus = {k: 0 for k in labels}\n",
    "    \n",
    "    for ix in range(0,len(words)):\n",
    "        candidate = words[ix]\n",
    "        cluster_label = labels[ix]\n",
    "        if candidate in ground_truths_hash:\n",
    "            ground_truths_in_clus[cluster_label] += 1\n",
    "            \n",
    "    return ground_truths_in_clus, cluster_frequency\n",
    "\n",
    "def get_homogeneity_proportion(ground_truths_in_clus, cluster_frequency):\n",
    "    return {k: ground_truths_in_clus[k]/cluster_frequency[k] for k in list(cluster_frequency)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danlg\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\optics_.py:791: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n"
     ]
    }
   ],
   "source": [
    "X = np.array(get_X_from_df(df_exp1.supervised_model_coords))\n",
    "X = pd.DataFrame(X)\n",
    "\n",
    "dbscan_labels = run_dbscan(X)\n",
    "agg_labels = run_agg_clustering(X)\n",
    "optics_labels = run_optics(X)\n",
    "df_exp1[\"db_scan_labels\"] = dbscan_labels\n",
    "df_exp1[\"agg_labels\"] = agg_labels\n",
    "df_exp1[\"optics_labels\"] = optics_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 1036})"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(run_dbscan(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df_exp1[\"db_scan_labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 50}, Counter({0: 1109}))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cluster_homogeneity(df_exp1.db_scan_labels,df_exp1.candidate,ground_truths_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 17, 1: 33}, Counter({0: 572, 1: 537}))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cluster_homogeneity(df_exp1.agg_labels,df_exp1.candidate,ground_truths_hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coordinates plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clus_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-126-904ffacf42bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mcolors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'blue'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'red'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'green'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'cyan'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'black'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'magenta'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mtsne_plot_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclus_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"db_scan_labels\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'clus_df' is not defined"
     ]
    }
   ],
   "source": [
    "def tsne_plot_candidates(model, df,colors, clus_labels_name, outfile = \"./clustering_coords.png\"):\n",
    "\n",
    "\n",
    "    tsne_model = TSNE(perplexity=5, n_components=2, init='pca', n_iter=250, random_state=23)\n",
    "    all_values = tsne_model.fit_transform(df)\n",
    "    \n",
    "    x0 = []\n",
    "    y0 = []\n",
    "\n",
    "    for value in all_values:\n",
    "        x0.append(value[0])\n",
    "        y0.append(value[1])\n",
    "        \n",
    "    plt.figure(figsize=(20, 20)) \n",
    "        \n",
    "    print(\"Beginning plotting..\")\n",
    "    for i in range(len(x0)):\n",
    "        plt.scatter(x0[i],y0[i], color=colors[df.loc[i,clus_labels_name]])\n",
    "\n",
    "        \n",
    "    plt.legend(colors.keys(), loc=\"upper left\")\n",
    "    plt.savefig(outfile, format=\"png\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "colors = {-1:'blue', 0: 'red', 1: 'green', 2: 'cyan', 3: 'black', 4: 'magenta'}\n",
    "tsne_plot_candidates(model, clus_df,colors,\"db_scan_labels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning plotting..\n",
      "{0: 'red', 1: 'black'}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = {0: 'red', 1: 'black'}\n",
    "tsne_plot_candidates(model, clus_df,colors,\"agg_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(agg_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run all models eight times\n",
    "\n",
    "Run each of the classifiers for the following 2 x 2 x 2 = 8 configurations:\n",
    "1. (all docs vs. fasttext-selected)\n",
    "1. (refined vs. unrefined)\n",
    "1. (word vector vs. score vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep a list of best models and best F scores\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Found error problem\n",
    "The error in the cell below is symbols that cannot be detected by unicode\n",
    "for ex... 700â€‰000 is one where the middle is replaces with \\u and it is re-intepreted to '700\\u2009000'\n",
    "This can be found in the excel sheet by searching 'SV-N-NA' and then moving over 2 cells. \n",
    "\n",
    "Another example is Mp = 1050âˆ’1â€‰870â€‰000 g/mol\n",
    "\n",
    "We need to figure out where file 'classifier_pipeline_candidates.csv' was created to potentially see how this came to be.\n",
    "\n",
    "In the meantime, a temp try except fix can be created but MUST be labeled in order for it to eventually be removed.\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results from running the models when trying to reproduce the original experiment were as follows. The data model from polymers.TEST file with the fasttext supervised training. \n",
    "Then, the refined model was run through the classification process where KNN, SVC with gridsearch, and RF with gridsearch were used to predict the candidate's valdiity. The results were as follows when doing this method...\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running all classifiers, with unrefined candidates; score vectors; full documents\n",
      "RUNNING THEM ALL NOW LENGTH OF X, y IS 1036 1036\n",
      "[[-0.19345038 -0.19081956 -0.18404378]\n",
      " [-0.67520261 -0.67415333 -0.63702399]\n",
      " [-0.50519967 -0.48787594 -0.47692698]\n",
      " ...\n",
      " [ 0.70991689  0.70786661  0.68097639]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.84394884  0.82795805  0.79854262]]\n",
      "K Nearest Neighbor:\n",
      "    Test points:     104\n",
      "    True positives:  8\n",
      "    False positive:  11\n",
      "    True negatives:  52\n",
      "    False negatives: 33\n",
      "    Precision:       0.421\n",
      "    Recall:          0.195\n",
      "    F-1 score:       0.267\n",
      "LEN X TRAIN 932\n",
      "LEN X TESST 104\n",
      "LEN Y PREDICTED 104\n",
      "{'y_predicted': array([1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "       0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'f1s': 0.26666666666666666}\n",
      "Support Vector:\n",
      "    Test points:     104\n",
      "    True positives:  0\n",
      "    False positive:  0\n",
      "    True negatives:  63\n",
      "    False negatives: 41\n",
      "    Precision:       0.000\n",
      "    Recall:          1.000\n",
      "    F-1 score:       -1.000\n",
      "Random Forest:\n",
      "    Test points:     104\n",
      "    True positives:  4\n",
      "    False positive:  22\n",
      "    True negatives:  41\n",
      "    False negatives: 37\n",
      "    Precision:       0.154\n",
      "    Recall:          0.098\n",
      "    F-1 score:       0.119\n",
      "K Nearest Neighbor achieves the best F1 score of 0.267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'knn_pred': array([1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'svc_pred': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'rf_pred': array([0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0])}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_full_documevbghnt_flag   = True\n",
    "refined_candidates_only_flag = False\n",
    "use_word_vector_flag         = False\n",
    "y = df_exp1.is_groundtruth.astype('int')\n",
    "\n",
    "predictions = run_all_models(X,y, results, process_full_document_flag, refined_candidates_only_flag, use_word_vector_flag)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Experiment 1 part 2: unsupervised word vectors</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'dict' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-204-9c85a8bc7e27>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdbscan_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_dbscan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0magg_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_agg_clustering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0moptics_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_optics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mdf_exp1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"db_scan_labels\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdbscan_labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdf_exp1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"agg_labels\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magg_labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-203-b9e6380e7852>\u001b[0m in \u001b[0;36mrun_optics\u001b[1;34m(X, **args)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrun_optics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0moptics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOPTICS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moptics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\optics_.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    246\u001b[0m              \u001b[0mleaf_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaf_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m              \u001b[0mmetric_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetric_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m              max_eps=self.max_eps)\n\u001b[0m\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# Extract clusters from the calculated orders and reachability\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\optics_.py\u001b[0m in \u001b[0;36mcompute_optics_graph\u001b[1;34m(X, min_samples, max_eps, metric, p, metric_params, algorithm, leaf_size, n_jobs)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \"\"\"\n\u001b[0;32m    437\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m     \u001b[0m_validate_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'min_samples'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmin_samples\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[0mmin_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_samples\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\optics_.py\u001b[0m in \u001b[0;36m_validate_size\u001b[1;34m(size, n_samples, param_name)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_validate_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 281\u001b[1;33m     if size <= 0 or (size !=\n\u001b[0m\u001b[0;32m    282\u001b[0m                      \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m                      and size > 1):\n",
      "\u001b[1;31mTypeError\u001b[0m: '<=' not supported between instances of 'dict' and 'int'"
     ]
    }
   ],
   "source": [
    "X = np.array(get_X_from_df(df_exp1.unsupervised_model_coords))\n",
    "X = pd.DataFrame(X)\n",
    "\n",
    "dbscan_labels = run_dbscan(X)\n",
    "agg_labels = run_agg_clustering(X)\n",
    "optics_labels = run_optics(X)\n",
    "df_exp1[\"db_scan_labels\"] = dbscan_labels\n",
    "df_exp1[\"agg_labels\"] = agg_labels\n",
    "df_exp1[\"optics_labels\"] = optics_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 1 sample(s) (shape=(1, 1036)) while a minimum of 2 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-128-58a1256c2e54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcolors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'red'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'black'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtsne_plot_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munsupervised_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdf_exp1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magg_labels\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"agg_labels\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-126-904ffacf42bd>\u001b[0m in \u001b[0;36mtsne_plot_candidates\u001b[1;34m(model, df, colors, clus_labels_name, outfile)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtsne_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperplexity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'pca'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m250\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m23\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mall_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtsne_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mx0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\manifold\\t_sne.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mEmbedding\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlow\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mdimensional\u001b[0m \u001b[0mspace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m         \"\"\"\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0membedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\manifold\\t_sne.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, skip_num_points)\u001b[0m\n\u001b[0;32m    698\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'barnes_hut'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m             X = check_array(X, ensure_min_samples=2,\n\u001b[1;32m--> 700\u001b[1;33m                             dtype=[np.float32, np.float64])\n\u001b[0m\u001b[0;32m    701\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m             X = check_array(X, accept_sparse=['csr', 'csc', 'coo'],\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    548\u001b[0m                              \u001b[1;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m                              % (n_samples, array.shape, ensure_min_samples,\n\u001b[1;32m--> 550\u001b[1;33m                                 context))\n\u001b[0m\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 1 sample(s) (shape=(1, 1036)) while a minimum of 2 is required."
     ]
    }
   ],
   "source": [
    "colors = {0: 'red', 1: 'black'}\n",
    "tsne_plot_candidates(unsupervised_model, [df_exp1.agg_labels],colors,\"agg_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running all classifiers, with unrefined candidates; word vectors; classified sentences\n",
      "RUNNING THEM ALL NOW LENGTH OF X, y IS 1036 1036\n",
      "[[0.42590395 0.39589396 0.63323128]\n",
      " [0.39300641 0.37277412 0.3996945 ]\n",
      " [0.17776731 0.21396039 0.24513222]\n",
      " ...\n",
      " [0.27501383 0.2774497  0.15923689]\n",
      " [0.42444849 0.41368377 0.2266674 ]\n",
      " [0.19565748 0.14148247 0.34373423]]\n",
      "K Nearest Neighbor:\n",
      "    Test points:     104\n",
      "    True positives:  17\n",
      "    False positive:  17\n",
      "    True negatives:  46\n",
      "    False negatives: 24\n",
      "    Precision:       0.500\n",
      "    Recall:          0.415\n",
      "    F-1 score:       0.453\n",
      "LEN X TRAIN 932\n",
      "LEN X TESST 104\n",
      "LEN Y PREDICTED 104\n",
      "{'y_predicted': array([1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
      "       1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "       0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0]), 'f1s': 0.4533333333333333}\n",
      "Support Vector:\n",
      "    Test points:     104\n",
      "    True positives:  7\n",
      "    False positive:  1\n",
      "    True negatives:  62\n",
      "    False negatives: 34\n",
      "    Precision:       0.875\n",
      "    Recall:          0.171\n",
      "    F-1 score:       0.286\n",
      "Random Forest:\n",
      "    Test points:     104\n",
      "    True positives:  10\n",
      "    False positive:  24\n",
      "    True negatives:  39\n",
      "    False negatives: 31\n",
      "    Precision:       0.294\n",
      "    Recall:          0.244\n",
      "    F-1 score:       0.267\n",
      "K Nearest Neighbor achieves the best F1 score of 0.453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'knn_pred': array([1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0]),\n",
       " 'svc_pred': array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'rf_pred': array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "        1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "        1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0])}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_full_document_flag   = False\n",
    "refined_candidates_only_flag = False\n",
    "use_word_vector_flag         = True\n",
    "\n",
    "y = df_exp1.is_groundtruth.astype('int')\n",
    "\n",
    "run_all_models(X, y, results, process_full_document_flag, refined_candidates_only_flag, use_word_vector_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score = 0.0\n",
    "for r in results:\n",
    "    ((method, f_score), _) = results[r]\n",
    "    if f_score > max_score:\n",
    "        max_method = method\n",
    "        max_config = r\n",
    "        max_score = f_score\n",
    "    print('%s: Classifier %s achieves the best f-score of %.3f' % (r, method, f_score))\n",
    "print('\\nBest overall score was %.3f for %s with %s' %(max_score, max_config, max_method))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Experiment 2 </h1> <br>\n",
    "This experiment will go through the idea from the exploratory data analysis done in the first part of this notebook,\n",
    "and will use new features to see how the classifiers and clustering performs.  This will include the following\n",
    "\n",
    "1. Add a feature for has_numeric. 1 if word has numeric AND has alphabetic chars, 0 else.\n",
    "2. n_dash - This feature value is  +1 for every \"-\" encounterd, else 0.\n",
    "3. n_parentheses - This feature value is +1 for every \"(\" and \")\" encountered, else 0.\n",
    "4. n_slash - This feature value is +1 for every \"/\" or \"\\\\\" encountered, else 0.\n",
    "5. contains_poly - returns 1 if \"poly\" in lowercase string, else 0.\n",
    "6. len string - length of the string\n",
    "7. will still contain a model.wv.similarity score against \"PS\" as a feature\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_partial_numeric(candidate):\n",
    "    has_non_numeric = False\n",
    "    has_numeric = False\n",
    "    \n",
    "    for char_ in candidate:\n",
    "        try:\n",
    "            char_numeric = int(char_)\n",
    "            has_numeric = True\n",
    "        except:\n",
    "            has_non_numeric = True\n",
    "            \n",
    "    return has_non_numeric and has_numeric\n",
    "\n",
    "def get_features(polymer_candidates, model, ground_truths_hash, refined_candidates_only_flag):\n",
    "\n",
    "    features = pd.DataFrame(columns=[\"has_numeric\",\"n_dash\",\"n_parentheses\",\"n_slash\",\"contains_poly\",\"len\",\"ps_similarity\",\"is_groudntruth\"])\n",
    "    \n",
    "    for candidate in polymer_candidates:        \n",
    "        #TRY used when non utc-8 chars are still inside the candidates. should probably solve this before final paper.\n",
    "        try:\n",
    "            similarity_score = round(model.wv.similarity(candidate,\"PS\"),2)\n",
    "            candidate_char_count = Counter(candidate)                \n",
    "\n",
    "            features = features.append({\n",
    "                \"has_numeric\": 1 if is_partial_numeric(candidate) else 0,\n",
    "                \"n_dash\": candidate_char_count[\"-\"],\n",
    "                \"n_parentheses\": candidate_char_count[\"(\"] + candidate_char_count[\")\"],\n",
    "                \"n_slash\": candidate_char_count[\"/\"] + candidate_char_count[\"\\\\\"],\n",
    "                \"contains_poly\": 1 if \"poly\" in candidate.lower() else 0,\n",
    "                \"len\": len(candidate),\n",
    "                \"ps_similarity\": similarity_score,\n",
    "                \"candidate\": candidate,\n",
    "                \"is_groundtruth\": 1 if candidate in ground_truths_hash else 0\n",
    "            },\n",
    "            ignore_index=True)\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "            \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_numeric</th>\n",
       "      <th>n_dash</th>\n",
       "      <th>n_parentheses</th>\n",
       "      <th>n_slash</th>\n",
       "      <th>contains_poly</th>\n",
       "      <th>len</th>\n",
       "      <th>ps_similarity</th>\n",
       "      <th>is_groudntruth</th>\n",
       "      <th>candidate</th>\n",
       "      <th>is_groundtruth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3-glycidoxypropyltrimethoxysilane</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mn ∼ 82 700 g/mol, Mw/Mn ∼ 1.09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dithranol</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tackiness</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PBDTC-TT1:PC70BM</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1412</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>octyl</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1413</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mw = 76.0 kg/mol</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1414</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>volumes</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1415</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thiol-terminated</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1416</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>silica</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1417 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     has_numeric n_dash n_parentheses n_slash contains_poly len  \\\n",
       "0              1      1             0       0             0  33   \n",
       "1              1      0             0       2             0  31   \n",
       "2              0      0             0       0             0   9   \n",
       "3              0      0             0       0             0   9   \n",
       "4              1      1             0       0             0  16   \n",
       "...          ...    ...           ...     ...           ...  ..   \n",
       "1412           0      0             0       0             0   5   \n",
       "1413           1      0             0       1             0  16   \n",
       "1414           0      0             0       0             0   7   \n",
       "1415           0      1             0       0             0  16   \n",
       "1416           0      0             0       0             0   6   \n",
       "\n",
       "      ps_similarity  is_groudntruth                          candidate  \\\n",
       "0              0.01             NaN  3-glycidoxypropyltrimethoxysilane   \n",
       "1              0.11             NaN    Mn ∼ 82 700 g/mol, Mw/Mn ∼ 1.09   \n",
       "2              0.07             NaN                          dithranol   \n",
       "3              0.10             NaN                          tackiness   \n",
       "4              0.19             NaN                   PBDTC-TT1:PC70BM   \n",
       "...             ...             ...                                ...   \n",
       "1412           0.02             NaN                              octyl   \n",
       "1413           0.18             NaN                   Mw = 76.0 kg/mol   \n",
       "1414           0.13             NaN                            volumes   \n",
       "1415           0.06             NaN                   thiol-terminated   \n",
       "1416           0.46             NaN                             silica   \n",
       "\n",
       "      is_groundtruth  \n",
       "0                0.0  \n",
       "1                0.0  \n",
       "2                0.0  \n",
       "3                0.0  \n",
       "4                0.0  \n",
       "...              ...  \n",
       "1412             0.0  \n",
       "1413             0.0  \n",
       "1414             0.0  \n",
       "1415             0.0  \n",
       "1416             0.0  \n",
       "\n",
       "[1417 rows x 10 columns]"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exp2 = get_features(candidates,model, ground_truths_hash, True)\n",
    "df_exp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "X = df_exp2[[\"has_numeric\",\"n_dash\",\"n_parentheses\",\"n_slash\",\"contains_poly\",\"len\",\"ps_similarity\"]]\n",
    "y = df_exp2[\"is_groundtruth\"].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running all classifiers, with unrefined candidates; score vectors; full documents\n",
      "RUNNING THEM ALL NOW LENGTH OF X, y IS 1417 1417\n",
      "[[1 0 0 ... 0 4 0.38999998569488525]\n",
      " [1 3 2 ... 1 45 0.07999999821186066]\n",
      " [0 1 0 ... 0 11 0.019999999552965164]\n",
      " ...\n",
      " [0 0 0 ... 0 3 0.36000001430511475]\n",
      " [0 0 0 ... 0 8 0.4399999976158142]\n",
      " [1 0 2 ... 0 15 0.25]]\n",
      "K Nearest Neighbor:\n",
      "    Test points:     142\n",
      "    True positives:  5\n",
      "    False positive:  7\n",
      "    True negatives:  118\n",
      "    False negatives: 12\n",
      "    Precision:       0.417\n",
      "    Recall:          0.294\n",
      "    F-1 score:       0.345\n",
      "LEN X TRAIN 1275\n",
      "LEN X TESST 142\n",
      "LEN Y PREDICTED 142\n",
      "{'y_predicted': array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0]), 'f1s': 0.3448275862068966}\n",
      "Support Vector:\n",
      "    Test points:     142\n",
      "    True positives:  3\n",
      "    False positive:  4\n",
      "    True negatives:  121\n",
      "    False negatives: 14\n",
      "    Precision:       0.429\n",
      "    Recall:          0.176\n",
      "    F-1 score:       0.250\n",
      "Random Forest:\n",
      "    Test points:     142\n",
      "    True positives:  4\n",
      "    False positive:  8\n",
      "    True negatives:  117\n",
      "    False negatives: 13\n",
      "    Precision:       0.333\n",
      "    Recall:          0.235\n",
      "    F-1 score:       0.276\n",
      "K Nearest Neighbor achieves the best F1 score of 0.345\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'knn_pred': array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " 'svc_pred': array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " 'rf_pred': array([0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_full_document_flag   = True\n",
    "refined_candidates_only_flag = False\n",
    "use_word_vector_flag         = False\n",
    "\n",
    "predictions = run_all_models(X,y, results, process_full_document_flag, refined_candidates_only_flag, use_word_vector_flag)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running all classifiers, with unrefined candidates; score vectors; classified sentences\n",
      "RUNNING THEM ALL NOW LENGTH OF X, y IS 1417 1417\n",
      "[[1 0 0 ... 0 4 0.38999998569488525]\n",
      " [1 3 2 ... 1 45 0.07999999821186066]\n",
      " [0 1 0 ... 0 11 0.019999999552965164]\n",
      " ...\n",
      " [0 0 0 ... 0 3 0.36000001430511475]\n",
      " [0 0 0 ... 0 8 0.4399999976158142]\n",
      " [1 0 2 ... 0 15 0.25]]\n",
      "K Nearest Neighbor:\n",
      "    Test points:     142\n",
      "    True positives:  5\n",
      "    False positive:  7\n",
      "    True negatives:  118\n",
      "    False negatives: 12\n",
      "    Precision:       0.417\n",
      "    Recall:          0.294\n",
      "    F-1 score:       0.345\n",
      "LEN X TRAIN 1275\n",
      "LEN X TESST 142\n",
      "LEN Y PREDICTED 142\n",
      "{'y_predicted': array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0]), 'f1s': 0.3448275862068966}\n",
      "Support Vector:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-323-bf434fd970da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0muse_word_vector_flag\u001b[0m         \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_all_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprocess_full_document_flag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrefined_candidates_only_flag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_word_vector_flag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-229-723cd09a2aad>\u001b[0m in \u001b[0;36mrun_all_models\u001b[1;34m(X, y, results, process_full_document_flag, refined_candidates_only_flag, use_word_vector_flag)\u001b[0m\n\u001b[0;32m     65\u001b[0m   \u001b[1;31m#  X, y = get_word_vectors_as_feature(connection, process_full_document_flag, refined_candidates_only_flag, use_word_vector_flag)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0mbest_model1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_f1_score1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_all_classifiers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'fulldoc'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mprocess_full_document_flag\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'classified_sentences'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'refined'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mrefined_candidates_only_flag\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'unrefined'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'words'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0muse_word_vector_flag\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'scores'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbest_model1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_f1_score1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-325179b4bf9a>\u001b[0m in \u001b[0;36mrun_all_classifiers\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Support Vector:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0msvc_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0msvc_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1_score2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvc_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y_predicted'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msvc_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'f1s'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mf1_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf1_score2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-229-723cd09a2aad>\u001b[0m in \u001b[0;36msvc\u001b[1;34m(Xtrain, Xtest, ytrain, ytest)\u001b[0m\n\u001b[0;32m     30\u001b[0m     clf = GridSearchCV(SVC(), tuned_parameters, cv=5,\n\u001b[0;32m     31\u001b[0m                        scoring='%s_macro' % scores[1])\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m     \u001b[1;31m#print(clf.best_params_)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    686\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1148\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    665\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 667\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    514\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    266\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "process_full_document_flag   = False\n",
    "refined_candidates_only_flag = False\n",
    "use_word_vector_flag         = False\n",
    "\n",
    "predictions = run_all_models(X,y, results, process_full_document_flag, refined_candidates_only_flag, use_word_vector_flag)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Next 11/3/2020 </h1>, take all candidates from here \\evaluation\\candidates\\listformat cluster them,\n",
    "id acronyms, and classify within that dataset. Try to look at cluster that contains acronym 'PS' .\n",
    "\n",
    "Also, KNN AUC (for probability levels of it being a groundtruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../candidates/listformat/full_doc_candidates_refined.txt',\"r\",encoding=\"utf-8\") as f:\n",
    "    fulldoc_candidates = []\n",
    "    for candidate in f.readlines():\n",
    "        fulldoc_candidates.append(candidate.strip(\"\\n\"))         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets ensure we focus only on refined candidaes, with value \"acceptable_after_refinement\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acceptable_after_refinement    924\n",
       "ignore_due_to_junk              24\n",
       "Name: is_refined, dtype: int64"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldoc_df = create_df(fulldoc_candidates,model=unsupervised_model,ground_truths=ground_truths)\n",
    "unsupervised_coords = get_similarity_scores_as_features(fulldoc_df.candidate, unsupervised_model,  [\"polystyrene\",\"poly(styrene)\",\"PS\"])\n",
    "fulldoc_df.unsupervised_coords = unsupervised_coords\n",
    "\n",
    "fulldoc_df.is_refined.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acceptable_after_refinement    924\n",
       "Name: is_refined, dtype: int64"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldoc_df = fulldoc_df[fulldoc_df.is_refined==\"acceptable_after_refinement\"]\n",
    "#fulldoc_df = fulldoc_df.reindex(range(len(fulldoc_df)))\n",
    "fulldoc_df.index = pd.RangeIndex(start=0,stop=len(fulldoc_df),step=1)\n",
    "\n",
    "fulldoc_df.is_refined.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(get_X_from_df(fulldoc_df.unsupervised_coords))\n",
    "X = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running clustering, let's define the logic needed\n",
    "to see which cluster \"PS\" is in, and see if this cluster is predominantly acronyms.<br>\n",
    "Additionally, we will create a function that writes to 3 files. The first file will contain the input parameters to the algorithm. The 2nd file will contain the statistics for homogeneity,\n",
    "and the third file will contain all the polymers that were found in the same cluster as \"PS\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def find_ps(df, labels):\n",
    "    \"\"\"returns the cluster term 'PS' is in, as well as all the candidates that were labeled with this cluster\"\"\"\n",
    "    ps_ix = df.candidate[fulldoc_df.candidate==\"PS\"].index[0]\n",
    "    ps_clus = labels[ps_ix]\n",
    "    df[\"cur_clus_labels\"] = labels\n",
    "    \n",
    "    candidates_in_clus = df[df.cur_clus_labels==ps_clus].candidate\n",
    "    \n",
    "    return ps_clus, candidates_in_clus\n",
    "\n",
    "def write_files(runs,algo):\n",
    "    for ix in range(len(runs)):\n",
    "        cur_run = runs[ix]\n",
    "        \n",
    "        with open('fulldocclustering/{}params{}.txt'.format(algo,str(ix)),'w') as f:\n",
    "            f.write(json.dumps(cur_run[\"params\"]))\n",
    "            \n",
    "        with open('fulldocclustering/{}homogeneity{}.txt'.format(algo,str(ix)),'w') as f:\n",
    "            f.write(\"total per clus: \\n\\n\")\n",
    "            total_per_clus = cur_run[\"total_per_clus\"]\n",
    "            total_per_clus_str = {str(k): str(total_per_clus[k]) for k in list(total_per_clus)}\n",
    "            f.write(json.dumps(total_per_clus_str)+'\\n')\n",
    "            \n",
    "            homogeneity_per_clus = cur_run[\"clus_homogeneity_proportion\"]\n",
    "            homogeneity_per_clus_str = {str(k): str(total_per_clus[k]) for k in list(homogeneity_per_clus)}\n",
    "            f.write(\"homogeneity proportion per clus: \\n\\n\")\n",
    "            f.write(json.dumps(homogeneity_per_clus_str))\n",
    "            \n",
    "        with open('fulldocclustering/{}ps_clus_cands{}.txt'.format(algo,str(ix)),'w',encoding='utf-8') as f:\n",
    "            ps_clus, cands_in_ps_clus = find_ps(fulldoc_df, cur_run[\"labels\"])\n",
    "            f.write(\"ps cluster label: {}\\n\\n\".format(str(ps_clus)))\n",
    "            for cand in cands_in_ps_clus:\n",
    "                f.write(cand+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>OPTICS clustering</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ground_truths_hash = \n",
    "opt_runs = []\n",
    "opt_min_samples = [5,8,11,14]\n",
    "opt_distances = [\"minkowski\",\"cosine\"]\n",
    "leaf_sizes = [20,25,30,35,40]\n",
    "\n",
    "for min_sample_size in opt_min_samples:\n",
    "    for metric in opt_distances:\n",
    "        for leaf_size in leaf_sizes:\n",
    "            params = {\"min_samples\":min_sample_size,\n",
    "                     \"metric\": metric,\n",
    "                     \"leaf_size\": leaf_size}\n",
    "            labels = run_optics(X,params)\n",
    "            \n",
    "            opt_gt_total, opt_counter = get_cluster_homogeneity(labels,fulldoc_df.candidate,ground_truths_hash)\n",
    "            proportion = get_homogeneity_proportion(opt_gt_total, opt_counter)\n",
    "            opt_runs.append({\"params\":params,\n",
    "                             \"labels\":labels,\n",
    "                             \"total_per_clus\":opt_counter,\n",
    "                             \"clus_homogeneity_proportion\": proportion})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_files(opt_runs,\"optics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Agglomerative Clustering </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_runs = []\n",
    "n_clusters = [2,3,4,5]\n",
    "agg_linkage = [\"ward\",\"complete\",\"average\",\"single\"]\n",
    "\n",
    "for cluster_size in n_clusters:\n",
    "    for linkage in agg_linkage:\n",
    "        params = {\"n_clusters\":min_sample_size,\n",
    "                     \"linkage\": linkage}\n",
    "        labels = run_agg_clustering(X,params)\n",
    "            \n",
    "        agg_gt_total, agg_counter = get_cluster_homogeneity(labels,fulldoc_df.candidate,ground_truths_hash)\n",
    "        proportion = get_homogeneity_proportion(agg_gt_total, agg_counter)\n",
    "        agg_runs.append({\"params\":params,\n",
    "                             \"labels\":labels,\n",
    "                             \"total_per_clus\":agg_counter,\n",
    "                             \"clus_homogeneity_proportion\": proportion})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "write_files(agg_runs,\"agg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>KMeans</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_runs = []\n",
    "k_params = [2,4,6,8,10,12]\n",
    "\n",
    "for k in k_params:\n",
    "    params = {\"n_clusters\":k}\n",
    "    labels = run_kmeans(X,params)\n",
    "            \n",
    "    kmeans_gt_total, kmeans_counter = get_cluster_homogeneity(labels,fulldoc_df.candidate,ground_truths_hash)\n",
    "    proportion = get_homogeneity_proportion(kmeans_gt_total, kmeans_counter)\n",
    "    kmeans_runs.append({\"params\":params,\n",
    "                    \"labels\":labels,\n",
    "                    \"total_per_clus\":kmeans_counter,\n",
    "                             \"clus_homogeneity_proportion\": proportion})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_files(kmeans_runs,\"kmeans\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
