{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification tests - Testing K Nearest Neighbors, Random Forest and Support Vector Classifications using a test set of 50 documents\n",
    "## Try these 3 different models to classify with word vectors of candidates generated via word2vec \n",
    "## Try these 3 different models to classify PS-similarity measures from candidates generated via word2vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from   __future__ import division\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "from   matplotlib.colors import ListedColormap\n",
    "from   sklearn import neighbors, datasets\n",
    "import gensim, logging\n",
    "from gensim.models import FastText\n",
    "import fasttext\n",
    "\n",
    "\n",
    "from   sklearn import svm\n",
    "from   sklearn.svm import SVR\n",
    "from   sklearn.svm import SVC\n",
    "from   sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import sklearn\n",
    "import spacy\n",
    "\n",
    "from   sklearn.model_selection import train_test_split\n",
    "from   sklearn.model_selection import GridSearchCV\n",
    "from   sklearn.metrics import classification_report\n",
    "from   sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from   sklearn.manifold import TSNE\n",
    "\n",
    "from   sklearn.ensemble import RandomForestRegressor\n",
    "from   sklearn.model_selection import train_test_split, GridSearchCV, ShuffleSplit\n",
    "import scipy as sp\n",
    "import _pickle as pkl\n",
    "#import cPickle as pkl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from   sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# This log shows progress and is very useful\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "# Load spacy for candidate processing\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# Adding these into the vocabulary\n",
    "nlp.vocab[u\"diblock\"].is_stop = False\n",
    "nlp.vocab[u\"g/mol\"].is_stop   = False\n",
    "nlp.vocab[u\"kg/mol\"].is_stop  = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUND_TRUTH_INPUT = \"../ground_truth/ground_truth_list_format.txt\"\n",
    "FULL_CANDIDATES = \"../../data/polymer_ner_evaluation.csv\"\n",
    "CBOW_MODEL = \"../../models/FT_cbow.bin\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we will create a file with all of the sentences from the processed_sentence column in \n",
    "sentences table. This file will serve as the training file for the fasttext unsupervised learning algorithm,\n",
    "and the vectors will then be used for clustering and classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to db\n",
    "def connect_to_db():\n",
    "    database = \"../../db/sentences.db\"\n",
    "    conn = create_connection(database)\n",
    "    return conn\n",
    "# Connect to DB\n",
    "def create_connection(db_file):\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    " \n",
    "    return None\n",
    "\n",
    "# Get sentences\n",
    "def get_sentences_from_db(conn):\n",
    "    sentences = ''\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"select processed_sentence from sentences\") \n",
    "    rows = cur.fetchall()\n",
    "    \n",
    "    with open('processed_sentences.txt','w',encoding=\"utf-8\") as f:\n",
    "        for row in rows:\n",
    "             f.write(row[0]+'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will train the FastText algorithm on polymers.test . The polymers.test includes 150 documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = connect_to_db()\n",
    "get_sentences_from_db(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we will get the models both for the supervised vectors and unsupervised vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_model = fasttext.train_supervised('../../data/polymers.test')\n",
    "unsupervised_model = fasttext.train_unsupervised('processed_sentences.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Exploration</h1> <br><br>\n",
    "First, we will take a look at the polymers from the ground_truth file and see which ones are the most popular based\n",
    "on their frequency in the data.test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_table(\"../../data/polymers.test\",encoding=\"utf-8\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_list_from_doc(test_data):\n",
    "    \"\"\"processes dfs where original file \n",
    "    is of the form [label, sentence] \"\"\"\n",
    "    \n",
    "    sentences_to_words = []\n",
    "    \n",
    "    df = pd.DataFrame(test_data[0].str.split(\" \",1))\n",
    "    sentences = df[0].str[1].apply(lambda x: x.lstrip('b'))\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        words = sentence.split(\" \")\n",
    "        for word in words:\n",
    "            sentences_to_words.append(word)\n",
    "    \n",
    "    return sentences_to_words\n",
    "\n",
    "def get_ground_truths(gt_input):\n",
    "    with open(gt_input, 'r') as f:\n",
    "        ground_truths = f.readlines()\n",
    "        \n",
    "    return [ground_truth.strip('\\n') for ground_truth in ground_truths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truths = get_ground_truths(GROUND_TRUTH_INPUT)\n",
    "word_counts = Counter(word_list_from_doc(test))\n",
    "word_counts_sorted = {k: v for k, v in sorted(word_counts.items(), key=lambda item: item[1],reverse=True)}\n",
    "ground_truth_counts = {k: word_counts[k] for k in ground_truths}\n",
    "ground_truth_counts = {k: v for k, v in sorted(ground_truth_counts.items(), key=lambda item: item[1],reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#word_counts_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ground_truth_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above, I have the following ideas...\n",
    "1. Add a feature for has_numeric. 1 if word has numeric AND has alphabetic chars, 0 else.\n",
    "2. has_dash - This returns 1 if contains \"-\", else 0.\n",
    "3. has_parentheses - This feature value is 1 if contains \"(\" and \")\" else 0.\n",
    "4. has_slash - 1 if contains \"/\" or \"\\\" else 0.\n",
    "5. contains_poly - returns 1 if \"poly\" in lowercase string, else 0. This is most questionable feature as this info should be somewhat accounted for in similarity measure vector approach\n",
    "6. len string - Also somewhat questionable as it could double based on similarity measure used against 3 common polymers. \n",
    "\n",
    "Proposal, keep \"PS\" similarity measure as feature to hopefully help find the abbreviated polymers. Remove other 2\n",
    "as those ones might fair better with binary attributes contains_poly and has_parentheses especially if using\n",
    "a tree based classification approach.\n",
    "\n",
    "Also, on top of the English word removal, potentially add common abbreviations such as i.e. and e.g. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets candidates from a fulldocument of candidates text file\n",
    "def get_fulldoc_candidates(doc_path):\n",
    "    with open(doc_path,'r', encoding='utf-8') as f:\n",
    "        candidates = f.readlines()\n",
    "        \n",
    "    return [candidate.strip('\\n') for candidate in candidates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_testing_data(features, target):\n",
    "    # Dataset, training and testing datasets\n",
    "    X = np.asarray(features)\n",
    "    y = np.asarray(target)\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(\n",
    "        X, y, test_size=0.1, random_state=0)\n",
    "    return Xtrain, Xtest, ytrain, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metrics - I think I can do that with scikit learn\n",
    "def metrics(predicted, actual):  \n",
    "    true_pos = 0\n",
    "    false_pos = 0\n",
    "    false_neg = 0\n",
    "    true_neg = 0\n",
    "    num_pos = 0\n",
    "    num_polys = 0\n",
    "    for i in range(len(predicted)):\n",
    "        if predicted[i] == 1 and actual[i] == 1:\n",
    "            true_pos = true_pos + 1\n",
    "        elif predicted[i] == 1 and actual[i] == 0:\n",
    "            false_pos = false_pos + 1\n",
    "        elif predicted[i] == 0 and actual[i] == 0:\n",
    "            true_neg = true_neg + 1\n",
    "        elif predicted[i] == 0 and actual[i] == 1:\n",
    "            false_neg = false_neg + 1\n",
    "\n",
    "    print('    Test points:     %d' % len(predicted))\n",
    "    print('    True positives:  %d' % true_pos)\n",
    "    print('    False positive:  %d' % false_pos)\n",
    "    print('    True negatives:  %d' % true_neg)\n",
    "    print('    False negatives: %d' % false_neg)\n",
    "    \n",
    "    if false_pos+true_pos > 0:\n",
    "        precision = true_pos/(true_pos+false_pos)\n",
    "\n",
    "        recall = true_pos/(true_pos+false_neg)\n",
    "        accuracy = (true_pos + true_neg)/(true_pos+true_neg+false_pos+false_neg)\n",
    "        f1score = 2/((1/recall)+(1/precision))\n",
    "    else: #FIXME\n",
    "        precision = 0\n",
    "        recall = 1\n",
    "        f1score = -1 #FIXME: check \n",
    "    print('    Precision:       %.3f' % precision)\n",
    "    print('    Recall:          %.3f' % recall)\n",
    "    #print \"Accuracy: \", accuracy / just to check my metrics function was correct\n",
    "    print('    F-1 score:       %.3f' %f1score)\n",
    "    #print clf.score(predicted,actual)\n",
    "    return f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if a string is a number\n",
    "def is_number(n):\n",
    "    try:\n",
    "        float(n)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# First use vectors as features\n",
    "def refine_candidate(candidate,model):\n",
    "    # Top context words in DB\n",
    "    frequent_context_words = [\"weight\",\"material\",\"system\",\"chains\",\"samples\", \"systems\",\"Tg\",\"weights\",\"comparison\",\"chromatography\",\"Mn\",\"THF\",\"toluene\",\"GPC\",\"chloroform\",\"index\",\"Column\",\"columns\",\"standards\",\"reference\",\"segments\",\"polydispersity\",\"substrate\",\"block\",\"components\",\"permeation\",\"component\",\"Mw\",\"bulk\",\"standard\",\"calibration\",\"dynamics\",\"cross-linked\",\"cells\",\"domains\",\"segment\",\"mixtures\",\"densities\",\"substrates\",\"well-defined\",\"silica\",\"SEC\",\"particles\",\"compositions\",\"surfaces\",\"linear\"]\n",
    "    \n",
    "    common_polys = ['polyethylene', 'polyurethane', 'polypropylene', 'polyester', 'PS', 'polystyrene', 'PLA', 'PI', 'PET', 'PVP', 'PEG', 'cellulose', 'PAN', 'methyl'] #These are polymers that could appear within spacy vocab\n",
    "    common_polys = [polymer.lower() for polymer in common_polys] \n",
    "\n",
    "    # Filter out junk values\n",
    "    junk_vals = []\n",
    "        \n",
    "    if (candidate in nlp.vocab) and candidate.lower() not in common_polys:\n",
    "        return \"ignore_due_to_english_word\"\n",
    "    \n",
    "    try:\n",
    "#         vocab_obj = model.get_word_vector(candidate) #model.wv.vocab[candidate]\n",
    "#         freq= vocab_obj.count\n",
    "\n",
    "        if candidate in frequent_context_words:\n",
    "            return \"ignore_due_to_context\"\n",
    "\n",
    "        junk = False\n",
    "        items = re.split(' |:|;|-',candidate)\n",
    "        for item in items:\n",
    "            #Removing items that are sentences within  parenthesis\n",
    "            if item != \"poly\" and is_number(item)==False and (\"standard\" in item or (item in nlp.vocab and item not in common_polys)):\n",
    "                junk = True\n",
    "                break\n",
    "\n",
    "        if junk is True:\n",
    "            return \"ignore_due_to_junk\"\n",
    "    except:\n",
    "        return \"ignore_due_to_not_in_model\"\n",
    "        \n",
    "    return \"acceptable_after_refinement\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define KNN, SVC, and RF models\n",
    "\n",
    "def knn(Xtrain,Xtest, ytrain, ytest):\n",
    "    # Number of neighbors 5 seems to work best\n",
    "    n_neighbors = 5\n",
    "\n",
    "    #for weights in ['uniform', 'distance']:\n",
    "    weights = 'uniform'\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)\n",
    "\n",
    "    clf.fit(Xtrain,ytrain)\n",
    "\n",
    "    y_predicted = clf.predict(Xtest)\n",
    "    f1s = metrics(y_predicted,ytest)\n",
    "    #print \"Classifier score (accuracy): \", clf.score(Xtest,ytest)\n",
    "   # return f1s\n",
    "    print(\"LEN X TRAIN {}\".format(str(len(Xtrain))))\n",
    "    print(\"LEN X TESST {}\".format(str(len(Xtest))))\n",
    "    print(\"LEN Y PREDICTED {}\".format(str(len(ytest))))\n",
    "    return {'y_predicted': y_predicted, 'f1s': f1s}\n",
    "\n",
    "\n",
    "def svc(Xtrain, Xtest, ytrain, ytest):\n",
    "    # Set the parameters by cross-validation\n",
    "    tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "    scores = ['precision', 'recall']\n",
    "    clf = GridSearchCV(SVC(), tuned_parameters, cv=5,\n",
    "                       scoring='%s_macro' % scores[1])\n",
    "    clf.fit(Xtrain, ytrain)\n",
    "    #print(clf.best_params_)\n",
    "    clf = clf.best_estimator_\n",
    "    y_pred = clf.predict(Xtest)\n",
    "    f1s = metrics(y_pred,ytest)\n",
    "   # return f1s\n",
    "    return {'y_predicted': y_pred, 'f1s': f1s}\n",
    "\n",
    "def RF(Xtrain, Xtest, ytrain, ytest):\n",
    "    param_grid = { \n",
    "        'max_features': ['auto', 'sqrt', 'log2']\n",
    "    }\n",
    "    \n",
    "    clf = RandomForestClassifier(max_depth=None, n_jobs=-1, max_features= 'sqrt' ,n_estimators=100, oob_score = True, random_state=None)\n",
    "    clf = GridSearchCV(RandomForestClassifier(n_estimators=100),\n",
    "                    param_grid=param_grid,\n",
    "                    scoring='f1',\n",
    "                    cv=10)\n",
    "    #clf = RandomForestClassifier(max_depth=None, max_features=3, random_state=None) # Change when using similarity scores\n",
    "    clf.fit(Xtrain, ytrain)\n",
    "    clf = clf.best_estimator_\n",
    "    y_predicted = clf.predict(Xtest)\n",
    "    f1s = metrics(y_predicted,ytest)\n",
    "   # return f1s\n",
    "    return {'y_predicted': y_predicted, 'f1s': f1s}\n",
    "\n",
    "\n",
    "def run_all_models(X, y, results, process_full_document_flag, refined_candidates_only_flag, use_word_vector_flag):\n",
    "    print('Running all classifiers, with %s candidates; %s; %s' % \n",
    "      ('refined' if refined_candidates_only_flag else 'unrefined',\n",
    "       'word vectors' if use_word_vector_flag else 'score vectors',\n",
    "       'full documents' if process_full_document_flag else 'classified sentences'))\n",
    "\n",
    "  #  X, y = get_word_vectors_as_feature(connection, process_full_document_flag, refined_candidates_only_flag, use_word_vector_flag)\n",
    "    \n",
    "    best_model1, max_f1_score1, predictions = run_all_classifiers(X, y)\n",
    "    key = ('fulldoc' if process_full_document_flag else 'classified_sentences') + '_' + ('refined' if refined_candidates_only_flag else 'unrefined') + '_' + ('words' if use_word_vector_flag else 'scores')\n",
    "    results[key] = [best_model1, max_f1_score1]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all classifiers on a particular type of input\n",
    "def run_all_classifiers(X,y):\n",
    "    print(\"RUNNING THEM ALL NOW LENGTH OF X, y IS {} {}\".format(str(len(X)),str(len(y))))\n",
    "    models = ['K Nearest Neighbor', 'Support Vector', 'Random Forest']\n",
    "    f1_scores = []\n",
    "    X_train, X_test, y_train, y_test = get_training_testing_data(X,y)\n",
    "    print(X_train)\n",
    "    print('K Nearest Neighbor:')\n",
    "    knn_results = knn(X_train, X_test, y_train, y_test)\n",
    "    print(knn_results)\n",
    "    knn_predictions,f1_score1 = knn_results['y_predicted'],knn_results['f1s']\n",
    "    f1_scores.append(f1_score1)\n",
    "    \n",
    "    print('Support Vector:')\n",
    "    svc_results = svc(X_train, X_test, y_train, y_test)\n",
    "    svc_predictions, f1_score2 = svc_results['y_predicted'], svc_results['f1s']\n",
    "    f1_scores.append(f1_score2)\n",
    "    \n",
    "    #print('Multi Layer Perceptron:')\n",
    "    #f1_score3 = MPC(X_train, X_test, y_train, y_test)\n",
    "    #print f1_score3\n",
    "    #f1_scores.append(f1_score3)\n",
    "    \n",
    "    print('Random Forest:')\n",
    "    rf_results = RF(X_train, X_test, y_train, y_test)\n",
    "    rf_predictions, f1_score4 = rf_results['y_predicted'],rf_results['f1s']\n",
    "    f1_scores.append(f1_score4)\n",
    "    max_f1 = max(f1_scores)\n",
    "    max_f1_index_arr = np.where(np.array(f1_scores)==max_f1)\n",
    "\n",
    "    for mf in range(len(max_f1_index_arr[0])):\n",
    "        max_f1_index = max_f1_index_arr[0][mf]\n",
    "        print ('%s achieves the best F1 score of %.3f' % (models[max_f1_index], f1_scores[max_f1_index]))\n",
    "    best_model = models[max_f1_index],f1_scores[max_f1_index]\n",
    "    \n",
    "    return(best_model, \n",
    "           max_f1,\n",
    "           {'knn_pred':knn_predictions,\n",
    "            'svc_pred':svc_predictions,\n",
    "            'rf_pred':rf_predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coords(words,model):\n",
    "    coords = []\n",
    "    for word in words:\n",
    "        try:\n",
    "            coords.append(model.wv.vocab[word])\n",
    "        except:\n",
    "            coords.append([0])\n",
    "        \n",
    "    return coords\n",
    "\n",
    "def get_similarity_scores_as_features(polymer_candidates, model, frequent_polymers):\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    # Polymers used to generate training data\n",
    "   # frequent_polymers = [\"polystyrene\",\"poly(styrene)\",\"PS\"]\n",
    "\n",
    "    features = {}\n",
    "    Xl = [] # vectors\n",
    "    yl = [] # target (is_poly=0:1?)\n",
    "    ll = [] # labels\n",
    "    \n",
    "   # similarities = {}\n",
    "    for candidate in polymer_candidates:\n",
    "        features[candidate] = []\n",
    "        candidate_vec = model.get_word_vector(candidate).reshape(1, -1)\n",
    "        \n",
    "        try:\n",
    "            for fp in frequent_polymers:\n",
    "                fp_vec = model.get_word_vector(fp).reshape(1, -1)\n",
    "                similarity_score = cosine_similarity(candidate_vec,fp_vec)#round(model.wv.similarity(candidate,fp),2)\n",
    "                features[candidate].append(similarity_score[0][0])\n",
    "\n",
    "            Xl.append(features[candidate])\n",
    "            yl.append(candidate)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "            \n",
    "    return Xl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clustering Setup ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hashes_from_list(list_):\n",
    "    \"\"\"returns dictionary with value 1 from a list. Its purpose is to be used when needing to find if \n",
    "    item is in a list repeatedly as this will get the find operation down to constant time.\"\"\"\n",
    "    return {key: 1 for key in list_}\n",
    "def create_df(candidates, model,ground_truths=None):\n",
    "    # is_{algo} columns are boolean as to whether or not they were predicted by that algorithm. \n",
    "    df = pd.DataFrame(columns=[\"candidate\",\"is_knn\",\"is_svc\",\"is_rf\",\"is_groundtruth\",\"db_scan_clus\",\"predictions\",\"is_refined\"])\n",
    "    #ground_truths_hashed = get_hashes_from_list(ground_truths)\n",
    "    \n",
    "    if isinstance(candidates,str):\n",
    "        with open(candidates,'r',encoding='utf-8') as candidates:\n",
    "            for candidate in candidates:\n",
    "                word_and_isgroundtruth = candidate.split(\"|\")\n",
    "                word = word_and_isgroundtruth[0].replace('\"','')\n",
    "                is_refined = refine_candidate(word, model)\n",
    "                is_groundtruth = int(word_and_isgroundtruth[1].replace('\"','').rstrip('\\n'))\n",
    "\n",
    "            # is_groundtruth = 1 if word in ground_truths_hash else 0\n",
    "                df = df.append({\"candidate\":word,\"is_groundtruth\":is_groundtruth,\"db_scan_clus\":None,\"supervised_coords\":[],\"unsupervised_coords\":[],\"is_refined\": is_refined},ignore_index=True)\n",
    "\n",
    "    else:\n",
    "        ground_truths_hashed = get_hashes_from_list(ground_truths)\n",
    "        for candidate in candidates:\n",
    "            is_refined = refine_candidate(candidate,model)\n",
    "            is_groundtruth = candidate in ground_truths_hashed\n",
    "            df = df.append({\"candidate\":candidate,\"is_groundtruth\":is_groundtruth,\"db_scan_clus\":None,\"supervised_coords\":[],\"unsupervised_coords\":[],\"is_refined\": is_refined},ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Experiment 1 </h1><br>\n",
    "The first experiment will be to go through the process as defined in the paper utilizing \n",
    "the terms from the 500 documents with the terms frfom the ground_truth file to see how clustering and the classifiers perform.\n",
    "This will use the cosine similaeity scores with the array [\"polystyrene\",\"poly(styrene)\",\"PS\"] as features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_exp1 = create_df(FULL_CANDIDATES, supervised_model)\n",
    "df_exp1 = df_exp1[df_exp1.is_refined==\"acceptable_after_refinement\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danlg\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "candidates = df_exp1.candidate\n",
    "supervised_coords = get_similarity_scores_as_features(candidates, supervised_model,  [\"polystyrene\",\"poly(styrene)\",\"PS\"])\n",
    "unsupervised_coords = get_similarity_scores_as_features(candidates, unsupervised_model,  [\"polystyrene\",\"poly(styrene)\",\"PS\"])\n",
    "df_exp1.supervised_model_coords = supervised_coords\n",
    "df_exp1.unsupervised_model_coords = unsupervised_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate</th>\n",
       "      <th>is_knn</th>\n",
       "      <th>is_svc</th>\n",
       "      <th>is_rf</th>\n",
       "      <th>is_groundtruth</th>\n",
       "      <th>db_scan_clus</th>\n",
       "      <th>predictions</th>\n",
       "      <th>is_refined</th>\n",
       "      <th>model_coords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DNA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acceptable_after_refinement</td>\n",
       "      <td>[-0.9956413, -0.9864065, -0.96618384]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>semidilute</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acceptable_after_refinement</td>\n",
       "      <td>[-0.9742995, -0.9674851, -0.95164067]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>well-entangled</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acceptable_after_refinement</td>\n",
       "      <td>[-0.63267654, -0.63258857, -0.60784334]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>fluids</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acceptable_after_refinement</td>\n",
       "      <td>[0.53739655, 0.52752966, 0.5192265]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>broad.23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acceptable_after_refinement</td>\n",
       "      <td>[0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1104</td>\n",
       "      <td>2 to 7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acceptable_after_refinement</td>\n",
       "      <td>[0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1105</td>\n",
       "      <td>polydimethylsiloxane</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acceptable_after_refinement</td>\n",
       "      <td>[0.9808457, 0.9674403, 0.9524896]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1106</td>\n",
       "      <td>four-armed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acceptable_after_refinement</td>\n",
       "      <td>[0.841585, 0.82723963, 0.8095096]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1107</td>\n",
       "      <td>rodlike</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acceptable_after_refinement</td>\n",
       "      <td>[-0.35197884, -0.35230455, -0.32604563]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1108</td>\n",
       "      <td>semicrystalline</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acceptable_after_refinement</td>\n",
       "      <td>[0.9917563, 0.9836085, 0.959339]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1036 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 candidate is_knn is_svc is_rf is_groundtruth db_scan_clus  \\\n",
       "0                      DNA      0      0     0              0         None   \n",
       "2               semidilute      0      0     0              0         None   \n",
       "3           well-entangled      0      0     0              0         None   \n",
       "7                   fluids      0      0     0              0         None   \n",
       "12                broad.23      0      0     0              0         None   \n",
       "...                    ...    ...    ...   ...            ...          ...   \n",
       "1104                2 to 7      0      0     0              1         None   \n",
       "1105  polydimethylsiloxane      0      0     0              1         None   \n",
       "1106            four-armed      0      0     0              1         None   \n",
       "1107               rodlike      0      0     0              1         None   \n",
       "1108       semicrystalline      0      0     0              1         None   \n",
       "\n",
       "     predictions                   is_refined  \\\n",
       "0            NaN  acceptable_after_refinement   \n",
       "2            NaN  acceptable_after_refinement   \n",
       "3            NaN  acceptable_after_refinement   \n",
       "7            NaN  acceptable_after_refinement   \n",
       "12           NaN  acceptable_after_refinement   \n",
       "...          ...                          ...   \n",
       "1104         NaN  acceptable_after_refinement   \n",
       "1105         NaN  acceptable_after_refinement   \n",
       "1106         NaN  acceptable_after_refinement   \n",
       "1107         NaN  acceptable_after_refinement   \n",
       "1108         NaN  acceptable_after_refinement   \n",
       "\n",
       "                                 model_coords  \n",
       "0       [-0.9956413, -0.9864065, -0.96618384]  \n",
       "2       [-0.9742995, -0.9674851, -0.95164067]  \n",
       "3     [-0.63267654, -0.63258857, -0.60784334]  \n",
       "7         [0.53739655, 0.52752966, 0.5192265]  \n",
       "12                            [0.0, 0.0, 0.0]  \n",
       "...                                       ...  \n",
       "1104                          [0.0, 0.0, 0.0]  \n",
       "1105        [0.9808457, 0.9674403, 0.9524896]  \n",
       "1106        [0.841585, 0.82723963, 0.8095096]  \n",
       "1107  [-0.35197884, -0.35230455, -0.32604563]  \n",
       "1108         [0.9917563, 0.9836085, 0.959339]  \n",
       "\n",
       "[1036 rows x 9 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_from_df(series_col):\n",
    "    arr = []\n",
    "    for coords in series_col:\n",
    "        arr.append([float(coord) for coord in coords])\n",
    "        \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read more about the algorithms...\n",
    "https://scikit-learn.org/stable/modules/clustering.html#optics\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.OPTICS.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(get_X_from_df(df_exp1.supervised_model_coords))\n",
    "X = pd.DataFrame(X)\n",
    "y = df_exp1.is_groundtruth.astype('int')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coordinates plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clus_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-126-904ffacf42bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mcolors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'blue'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'red'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'green'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'cyan'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'black'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'magenta'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mtsne_plot_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclus_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"db_scan_labels\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'clus_df' is not defined"
     ]
    }
   ],
   "source": [
    "def tsne_plot_candidates(model, df,colors, clus_labels_name, outfile = \"./clustering_coords.png\"):\n",
    "\n",
    "\n",
    "    tsne_model = TSNE(perplexity=5, n_components=2, init='pca', n_iter=250, random_state=23)\n",
    "    all_values = tsne_model.fit_transform(df)\n",
    "    \n",
    "    x0 = []\n",
    "    y0 = []\n",
    "\n",
    "    for value in all_values:\n",
    "        x0.append(value[0])\n",
    "        y0.append(value[1])\n",
    "        \n",
    "    plt.figure(figsize=(20, 20)) \n",
    "        \n",
    "    print(\"Beginning plotting..\")\n",
    "    for i in range(len(x0)):\n",
    "        plt.scatter(x0[i],y0[i], color=colors[df.loc[i,clus_labels_name]])\n",
    "\n",
    "        \n",
    "    plt.legend(colors.keys(), loc=\"upper left\")\n",
    "    plt.savefig(outfile, format=\"png\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "colors = {-1:'blue', 0: 'red', 1: 'green', 2: 'cyan', 3: 'black', 4: 'magenta'}\n",
    "tsne_plot_candidates(model, clus_df,colors,\"db_scan_labels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning plotting..\n",
      "{0: 'red', 1: 'black'}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = {0: 'red', 1: 'black'}\n",
    "tsne_plot_candidates(model, clus_df,colors,\"agg_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(agg_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run all models eight times\n",
    "\n",
    "Run each of the classifiers for the following 2 x 2 x 2 = 8 configurations:\n",
    "1. (all docs vs. fasttext-selected)\n",
    "1. (refined vs. unrefined)\n",
    "1. (word vector vs. score vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep a list of best models and best F scores\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Found error problem\n",
    "The error in the cell below is symbols that cannot be detected by unicode\n",
    "for ex... 700â€‰000 is one where the middle is replaces with \\u and it is re-intepreted to '700\\u2009000'\n",
    "This can be found in the excel sheet by searching 'SV-N-NA' and then moving over 2 cells. \n",
    "\n",
    "Another example is Mp = 1050âˆ’1â€‰870â€‰000 g/mol\n",
    "\n",
    "We need to figure out where file 'classifier_pipeline_candidates.csv' was created to potentially see how this came to be.\n",
    "\n",
    "In the meantime, a temp try except fix can be created but MUST be labeled in order for it to eventually be removed.\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results from running the models when trying to reproduce the original experiment were as follows. The data model from polymers.TEST file with the fasttext supervised training. \n",
    "Then, the refined model was run through the classification process where KNN, SVC with gridsearch, and RF with gridsearch were used to predict the candidate's valdiity. The results were as follows when doing this method...\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running all classifiers, with unrefined candidates; score vectors; full documents\n",
      "RUNNING THEM ALL NOW LENGTH OF X, y IS 1036 1036\n",
      "[[-0.19345038 -0.19081956 -0.18404378]\n",
      " [-0.67520261 -0.67415333 -0.63702399]\n",
      " [-0.50519967 -0.48787594 -0.47692698]\n",
      " ...\n",
      " [ 0.70991689  0.70786661  0.68097639]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.84394884  0.82795805  0.79854262]]\n",
      "K Nearest Neighbor:\n",
      "    Test points:     104\n",
      "    True positives:  8\n",
      "    False positive:  11\n",
      "    True negatives:  52\n",
      "    False negatives: 33\n",
      "    Precision:       0.421\n",
      "    Recall:          0.195\n",
      "    F-1 score:       0.267\n",
      "LEN X TRAIN 932\n",
      "LEN X TESST 104\n",
      "LEN Y PREDICTED 104\n",
      "{'y_predicted': array([1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "       0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'f1s': 0.26666666666666666}\n",
      "Support Vector:\n",
      "    Test points:     104\n",
      "    True positives:  0\n",
      "    False positive:  0\n",
      "    True negatives:  63\n",
      "    False negatives: 41\n",
      "    Precision:       0.000\n",
      "    Recall:          1.000\n",
      "    F-1 score:       -1.000\n",
      "Random Forest:\n",
      "    Test points:     104\n",
      "    True positives:  4\n",
      "    False positive:  22\n",
      "    True negatives:  41\n",
      "    False negatives: 37\n",
      "    Precision:       0.154\n",
      "    Recall:          0.098\n",
      "    F-1 score:       0.119\n",
      "K Nearest Neighbor achieves the best F1 score of 0.267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'knn_pred': array([1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'svc_pred': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'rf_pred': array([0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0])}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_full_documevbghnt_flag   = True\n",
    "refined_candidates_only_flag = False\n",
    "use_word_vector_flag         = False\n",
    "\n",
    "predictions = run_all_models(X,y, results, process_full_document_flag, refined_candidates_only_flag, use_word_vector_flag)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Experiment 1 part 2: unsupervised word vectors</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1036, 3) (1036,)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(get_X_from_df(df_exp1.unsupervised_model_coords))\n",
    "X = pd.DataFrame(X)\n",
    "y = df_exp1.is_groundtruth.astype('int')\n",
    "\n",
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors = {0: 'red', 1: 'black'}\n",
    "# tsne_plot_candidates(unsupervised_model, [df_exp1.agg_labels],colors,\"agg_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running all classifiers, with unrefined candidates; word vectors; classified sentences\n",
      "RUNNING THEM ALL NOW LENGTH OF X, y IS 1036 1036\n",
      "[[0.42590395 0.39589396 0.63323128]\n",
      " [0.39300641 0.37277412 0.3996945 ]\n",
      " [0.17776731 0.21396039 0.24513222]\n",
      " ...\n",
      " [0.27501383 0.2774497  0.15923689]\n",
      " [0.42444849 0.41368377 0.2266674 ]\n",
      " [0.19565748 0.14148247 0.34373423]]\n",
      "K Nearest Neighbor:\n",
      "    Test points:     104\n",
      "    True positives:  17\n",
      "    False positive:  17\n",
      "    True negatives:  46\n",
      "    False negatives: 24\n",
      "    Precision:       0.500\n",
      "    Recall:          0.415\n",
      "    F-1 score:       0.453\n",
      "LEN X TRAIN 932\n",
      "LEN X TESST 104\n",
      "LEN Y PREDICTED 104\n",
      "{'y_predicted': array([1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
      "       1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "       0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0]), 'f1s': 0.4533333333333333}\n",
      "Support Vector:\n",
      "    Test points:     104\n",
      "    True positives:  7\n",
      "    False positive:  1\n",
      "    True negatives:  62\n",
      "    False negatives: 34\n",
      "    Precision:       0.875\n",
      "    Recall:          0.171\n",
      "    F-1 score:       0.286\n",
      "Random Forest:\n",
      "    Test points:     104\n",
      "    True positives:  10\n",
      "    False positive:  24\n",
      "    True negatives:  39\n",
      "    False negatives: 31\n",
      "    Precision:       0.294\n",
      "    Recall:          0.244\n",
      "    F-1 score:       0.267\n",
      "K Nearest Neighbor achieves the best F1 score of 0.453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'knn_pred': array([1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0]),\n",
       " 'svc_pred': array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'rf_pred': array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "        1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "        1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0])}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_full_document_flag   = False\n",
    "refined_candidates_only_flag = False\n",
    "use_word_vector_flag         = True\n",
    "\n",
    "\n",
    "run_all_models(X, y, results, process_full_document_flag, refined_candidates_only_flag, use_word_vector_flag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, the unsupervised feature vectors that were taken from the entire set \n",
    "appear to have performed better in classification than the fasttext supervised\n",
    "feature vectors taken from the 50 documents in every classifier. The KNN \n",
    "classifier stood out as the best performing one consistently in the above steps that try \n",
    "to reproduce the original research results. \n",
    "\n",
    "Below, we will create a gridsearch KNN, and then will check to see if probability cutoffs help improve the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 28 candidates, totalling 84 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  84 out of  84 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def knn_optimize(X_train,X_test,y_train,y_test):\n",
    "    grid_params = {\n",
    "        'n_neighbors': [3,5,7,9,11,13,15],\n",
    "        'weights': ['uniform','distance'],\n",
    "        'metric': ['euclidean','manhattan']\n",
    "    }\n",
    "    gs = GridSearchCV(\n",
    "    neighbors.KNeighborsClassifier(),\n",
    "    grid_params,\n",
    "    verbose=1,\n",
    "    cv=3,\n",
    "    n_jobs=-1)\n",
    "    \n",
    "    gs_results = gs.fit(X_train,y_train)\n",
    "    \n",
    "    knn_cf = neighbors.KNeighborsClassifier(**gs_results.best_params_)\n",
    "    knn_cf.fit(X_train,y_train)\n",
    "    knn_pred_proba = knn_cf.predict_proba(X_test)\n",
    "    knn_pred = knn_cf.predict(X_test)\n",
    "    \n",
    "    return gs_results,knn_pred_proba,knn_pred\n",
    "\n",
    "def prob_optimize(y_pred_prob,y_test, cutoffs):\n",
    "    \n",
    "    f1_score_ls = []\n",
    "    recall_ls = []\n",
    "    precision_ls = []\n",
    "    \n",
    "    for cutoff in cutoffs:\n",
    "        cutoff_pred = [1 if y[1] >= cutoff else 0 for y in y_pred_prob]\n",
    "        f1_score_ls.append(f1_score(y_test,cutoff_pred))\n",
    "        recall_ls.append(recall_score(y_test,cutoff_pred))\n",
    "        precision_ls.append(precision_score(y_test,cutoff_pred))\n",
    "        \n",
    "    return {'f1_score':f1_score_ls,\n",
    "           'recall': recall_ls,\n",
    "           'precision': precision_ls}\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "knn_gs, knn_pred_proba, knn_pred = knn_optimize(X_train,X_test,y_train,y_test)\n",
    "\n",
    "cutoffs = [0.3,0.4,0.5,0.6,0.7,0.8]\n",
    "cutoff_scores = prob_optimize(knn_pred_proba,y_test,cutoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2cc8598edc8>"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cutoffs,cutoff_scores['f1_score'],label=\"f1_score\")\n",
    "plt.plot(cutoffs,cutoff_scores['recall'],label=\"recall\")\n",
    "plt.plot(cutoffs,cutoff_scores['precision'],label=\"precision\")\n",
    "plt.legend(loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, it can be seen that a probability cutoff of 0.4 yields the best results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Experiment 2 </h1> <br>\n",
    "This experiment will go through the idea from the exploratory data analysis done in the first part of this notebook,\n",
    "and will use new features to see how the classifiers and clustering performs.  This will include the following\n",
    "\n",
    "1. Add a feature for has_numeric. 1 if word has numeric AND has alphabetic chars, 0 else.\n",
    "2. n_dash - This feature value is  +1 for every \"-\" encounterd, else 0.\n",
    "3. n_parentheses - This feature value is +1 for every \"(\" and \")\" encountered, else 0.\n",
    "4. n_slash - This feature value is +1 for every \"/\" or \"\\\\\" encountered, else 0.\n",
    "5. contains_poly - returns 1 if \"poly\" in lowercase string, else 0.\n",
    "6. len string - length of the string\n",
    "7. will still contain a model.wv.similarity score against \"PS\" as a feature\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_partial_numeric(candidate):\n",
    "    has_non_numeric = False\n",
    "    has_numeric = False\n",
    "    \n",
    "    for char_ in candidate:\n",
    "        try:\n",
    "            char_numeric = int(char_)\n",
    "            has_numeric = True\n",
    "        except:\n",
    "            has_non_numeric = True\n",
    "            \n",
    "    return has_non_numeric and has_numeric\n",
    "\n",
    "def get_exp2_features(polymer_candidates, model, ground_truths_hash, refined_candidates_only_flag):\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    features = pd.DataFrame(columns=[\"has_numeric\",\"n_dash\",\"n_parentheses\",\"n_slash\",\"contains_poly\",\"len\",\"ps_similarity\",\"is_groudntruth\"])\n",
    "    \n",
    "    ps_wv = model.get_word_vector(\"PS\").reshape(1, -1)\n",
    "    for candidate in polymer_candidates:        \n",
    "        #TRY used when non utc-8 chars are still inside the candidates. should probably solve this before final paper.\n",
    "        try:\n",
    "            candidate_wv = model.get_word_vector(candidate).reshape(1, -1)\n",
    "            \n",
    "            similarity_score = cosine_similarity(candidate_wv,ps_wv)\n",
    "            candidate_char_count = Counter(candidate)                \n",
    "\n",
    "            features = features.append({\n",
    "                \"has_numeric\": 1 if is_partial_numeric(candidate) else 0,\n",
    "                \"n_dash\": candidate_char_count[\"-\"],\n",
    "                \"n_parentheses\": candidate_char_count[\"(\"] + candidate_char_count[\")\"],\n",
    "                \"n_slash\": candidate_char_count[\"/\"] + candidate_char_count[\"\\\\\"],\n",
    "                \"contains_poly\": 1 if \"poly\" in candidate.lower() else 0,\n",
    "                \"len\": len(candidate),\n",
    "                \"ps_similarity\": similarity_score[0][0],\n",
    "                \"candidate\": candidate,\n",
    "                \"is_groundtruth\": 1 if candidate in ground_truths_hash else 0\n",
    "            },\n",
    "            ignore_index=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "        \n",
    "            \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_numeric</th>\n",
       "      <th>n_dash</th>\n",
       "      <th>n_parentheses</th>\n",
       "      <th>n_slash</th>\n",
       "      <th>contains_poly</th>\n",
       "      <th>len</th>\n",
       "      <th>ps_similarity</th>\n",
       "      <th>is_groudntruth</th>\n",
       "      <th>candidate</th>\n",
       "      <th>is_groundtruth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.132792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DNA</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.276306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>semidilute</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.399695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>well-entangled</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.206514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fluids</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.354533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>broad.23</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1031</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.268286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2 to 7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.441727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>polydimethylsiloxane</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1033</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.323519</td>\n",
       "      <td>NaN</td>\n",
       "      <td>four-armed</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1034</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.311573</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rodlike</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1035</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.294540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>semicrystalline</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1036 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     has_numeric n_dash n_parentheses n_slash contains_poly len  \\\n",
       "0              0      0             0       0             0   3   \n",
       "1              0      0             0       0             0  10   \n",
       "2              0      1             0       0             0  14   \n",
       "3              0      0             0       0             0   6   \n",
       "4              1      0             0       0             0   8   \n",
       "...          ...    ...           ...     ...           ...  ..   \n",
       "1031           1      0             0       0             0   6   \n",
       "1032           0      0             0       0             1  20   \n",
       "1033           0      1             0       0             0  10   \n",
       "1034           0      0             0       0             0   7   \n",
       "1035           0      0             0       0             0  15   \n",
       "\n",
       "      ps_similarity  is_groudntruth             candidate  is_groundtruth  \n",
       "0          0.132792             NaN                   DNA             0.0  \n",
       "1          0.276306             NaN            semidilute             0.0  \n",
       "2          0.399695             NaN        well-entangled             0.0  \n",
       "3          0.206514             NaN                fluids             0.0  \n",
       "4          0.354533             NaN              broad.23             0.0  \n",
       "...             ...             ...                   ...             ...  \n",
       "1031       0.268286             NaN                2 to 7             0.0  \n",
       "1032       0.441727             NaN  polydimethylsiloxane             1.0  \n",
       "1033       0.323519             NaN            four-armed             0.0  \n",
       "1034       0.311573             NaN               rodlike             0.0  \n",
       "1035       0.294540             NaN       semicrystalline             0.0  \n",
       "\n",
       "[1036 rows x 10 columns]"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exp2 = get_exp2_features(candidates,unsupervised_model, ground_truths_hash, True)\n",
    "df_exp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "X = df_exp2[[\"has_numeric\",\"n_dash\",\"n_parentheses\",\"n_slash\",\"contains_poly\",\"len\",\"ps_similarity\"]]\n",
    "y = df_exp2[\"is_groundtruth\"].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running all classifiers, with unrefined candidates; score vectors; full documents\n",
      "RUNNING THEM ALL NOW LENGTH OF X, y IS 1036 1036\n",
      "[[1 0 0 ... 0 6 0.6332312822341919]\n",
      " [0 1 0 ... 0 14 0.3996945023536682]\n",
      " [0 0 0 ... 0 14 0.2451322227716446]\n",
      " ...\n",
      " [0 0 0 ... 0 8 0.15923689305782318]\n",
      " [0 0 0 ... 0 10 0.2266674041748047]\n",
      " [0 2 0 ... 0 20 0.3437342345714569]]\n",
      "K Nearest Neighbor:\n",
      "    Test points:     104\n",
      "    True positives:  0\n",
      "    False positive:  1\n",
      "    True negatives:  98\n",
      "    False negatives: 5\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-486-22df80e09996>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0muse_word_vector_flag\u001b[0m         \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_all_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprocess_full_document_flag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrefined_candidates_only_flag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_word_vector_flag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-54-723cd09a2aad>\u001b[0m in \u001b[0;36mrun_all_models\u001b[1;34m(X, y, results, process_full_document_flag, refined_candidates_only_flag, use_word_vector_flag)\u001b[0m\n\u001b[0;32m     65\u001b[0m   \u001b[1;31m#  X, y = get_word_vectors_as_feature(connection, process_full_document_flag, refined_candidates_only_flag, use_word_vector_flag)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0mbest_model1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_f1_score1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_all_classifiers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'fulldoc'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mprocess_full_document_flag\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'classified_sentences'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'refined'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mrefined_candidates_only_flag\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'unrefined'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'words'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0muse_word_vector_flag\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'scores'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbest_model1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_f1_score1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-42-325179b4bf9a>\u001b[0m in \u001b[0;36mrun_all_classifiers\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'K Nearest Neighbor:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mknn_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mknn_results\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mknn_predictions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf1_score1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y_predicted'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mknn_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'f1s'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-54-723cd09a2aad>\u001b[0m in \u001b[0;36mknn\u001b[1;34m(Xtrain, Xtest, ytrain, ytest)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0my_predicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mf1s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_predicted\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;31m#print \"Classifier score (accuracy): \", clf.score(Xtest,ytest)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m    \u001b[1;31m# return f1s\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-40-fd799b2bcbe9>\u001b[0m in \u001b[0;36mmetrics\u001b[1;34m(predicted, actual)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mrecall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrue_pos\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrue_pos\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfalse_neg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrue_pos\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtrue_neg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrue_pos\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtrue_neg\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfalse_pos\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfalse_neg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mf1score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mrecall\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mprecision\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#FIXME\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mprecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "process_full_document_flag   = True\n",
    "refined_candidates_only_flag = False\n",
    "use_word_vector_flag         = False\n",
    "\n",
    "predictions = run_all_models(X,y, results, process_full_document_flag, refined_candidates_only_flag, use_word_vector_flag)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 28 candidates, totalling 84 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done  61 out of  84 | elapsed:    4.0s remaining:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  84 out of  84 | elapsed:    4.0s finished\n",
      "C:\\Users\\danlg\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\danlg\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "knn_gs, knn_pred_proba, knn_pred = knn_optimize(X_train,X_test,y_train,y_test)\n",
    "\n",
    "cutoffs = [0.3,0.4,0.5,0.6,0.7,0.8]\n",
    "cutoff_scores = prob_optimize(knn_pred_proba,y_test,cutoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2cc859dd8c8>"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cutoffs,cutoff_scores['f1_score'],label=\"f1_score\")\n",
    "plt.plot(cutoffs,cutoff_scores['recall'],label=\"recall\")\n",
    "plt.plot(cutoffs,cutoff_scores['precision'],label=\"precision\")\n",
    "plt.legend(loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Next 11/3/2020 </h1>, take all candidates from here \\evaluation\\candidates\\listformat cluster them, (100 docs)\n",
    "id acronyms, and classify within that dataset. Try to look at cluster that contains acronym 'PS' .\n",
    "\n",
    "Also, KNN AUC (for probability levels of it being a groundtruth)\n",
    "\n",
    "Also, next 11/10/20, add the other acronyms from https://github.com/rtchoua/WordEmbeddingNER/blob/master/2_word_embedding_model1_gensim.ipynb and find their clusters as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_cluster_homogeneity(labels,words,ground_truths_hash):\n",
    "    cluster_frequency = Counter(labels)\n",
    "    ground_truths_in_clus = {k: 0 for k in labels}\n",
    "    \n",
    "    for ix in range(0,len(words)):\n",
    "        candidate = words[ix]\n",
    "        cluster_label = labels[ix]\n",
    "        if candidate in ground_truths_hash:\n",
    "            ground_truths_in_clus[cluster_label] += 1\n",
    "            \n",
    "    return ground_truths_in_clus, cluster_frequency\n",
    "\n",
    "def get_homogeneity_proportion(ground_truths_in_clus, cluster_frequency):\n",
    "    return {k: ground_truths_in_clus[k]/cluster_frequency[k] for k in list(cluster_frequency)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN, AgglomerativeClustering, OPTICS, KMeans\n",
    "\n",
    "def run_dbscan(X):\n",
    "    clustering = DBSCAN().fit(X)\n",
    "    return clustering.labels_\n",
    "    \n",
    "def run_kmeans(X,params):\n",
    "    clustering = KMeans(**params).fit(X)\n",
    "    return clustering.labels_\n",
    "\n",
    "def run_optics(X,args):\n",
    "    optics = OPTICS(**args).fit(X)\n",
    "    return optics.labels_\n",
    "\n",
    "def run_agg_clustering(X,args):\n",
    "    clustering = AgglomerativeClustering(**args).fit(X)\n",
    "    return clustering.labels_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../candidates/listformat/full_doc_candidates_refined.txt',\"r\",encoding=\"utf-8\") as f:\n",
    "    fulldoc_candidates = []\n",
    "    for candidate in f.readlines():\n",
    "        fulldoc_candidates.append(candidate.strip(\"\\n\"))         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets ensure we focus only on refined candidaes, with value \"acceptable_after_refinement\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acceptable_after_refinement    924\n",
       "ignore_due_to_junk              24\n",
       "Name: is_refined, dtype: int64"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldoc_df = create_df(fulldoc_candidates,model=unsupervised_model,ground_truths=ground_truths)\n",
    "unsupervised_coords = get_similarity_scores_as_features(fulldoc_df.candidate, unsupervised_model,  [\"polystyrene\",\"poly(styrene)\",\"PS\"])\n",
    "fulldoc_df.unsupervised_coords = unsupervised_coords\n",
    "\n",
    "fulldoc_df.is_refined.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acceptable_after_refinement    924\n",
       "Name: is_refined, dtype: int64"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldoc_df = fulldoc_df[fulldoc_df.is_refined==\"acceptable_after_refinement\"]\n",
    "#fulldoc_df = fulldoc_df.reindex(range(len(fulldoc_df)))\n",
    "fulldoc_df.index = pd.RangeIndex(start=0,stop=len(fulldoc_df),step=1)\n",
    "\n",
    "fulldoc_df.is_refined.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(get_X_from_df(fulldoc_df.unsupervised_coords))\n",
    "X = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running clustering, let's define the logic needed\n",
    "to see which cluster \"PS\" is in, and see if this cluster is predominantly acronyms.<br>\n",
    "Additionally, we will create a function that writes to 3 files. The first file will contain the input parameters to the algorithm. The 2nd file will contain the statistics for homogeneity,\n",
    "and the third file will contain all the polymers that were found in the same cluster as \"PS\". Also, draw Silhouette curve for the clusters. We will be focusing on Agglomerative going forward.<br><br>https://github.com/rtchoua/WordEmbeddingNER/blob/master/2_word_embedding_model1_gensim.ipynb\n",
    "PMMA\n",
    "PEO\n",
    "https://docs.google.com/document/d/1bg1gcx_V1Ze2mYY3n1GQN2qb4neBKypYgazUreKfa68/edit\n",
    "Snorkel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def find_acronyms(df, labels, acronyms):\n",
    "    \"\"\"returns the clusters acronyms are in, as well as all the candidates that were labeled with this cluster\"\"\"\n",
    "    candidates_in_clus = []\n",
    "    acronym_clusters = []\n",
    "    df[\"clus_labels\"] = labels\n",
    "\n",
    "    acronym_clus = []\n",
    "    for acronym in acronyms:\n",
    "        acronym_ix = df.candidate[fulldoc_df.candidate==acronym].index[0]\n",
    "        cur_acronym_clus = labels[acronym_ix]\n",
    "        acronym_clusters.append(cur_acronym_clus)\n",
    "        candidates_in_clus += [candidate for candidate in df[df.clus_labels==cur_acronym_clus].candidate]\n",
    "    \n",
    "    return acronym_clusters, candidates_in_clus\n",
    "\n",
    "def write_files(runs,algo,acronyms):\n",
    "    acronyms_str = ''.join(acronyms)\n",
    "    for ix in range(len(runs)):\n",
    "        cur_run = runs[ix]\n",
    "        \n",
    "        with open('fulldocclustering/{}params{}{}.txt'.format(algo,str(ix),acronyms_str),'w') as f:\n",
    "            f.write(json.dumps(cur_run[\"params\"]))\n",
    "            \n",
    "        with open('fulldocclustering/{}homogeneity{}{}.txt'.format(algo,str(ix),acronyms_str),'w') as f:\n",
    "            f.write(\"total per clus: \\n\\n\")\n",
    "            total_per_clus = cur_run[\"total_per_clus\"]\n",
    "            total_per_clus_str = {str(k): str(total_per_clus[k]) for k in list(total_per_clus)}\n",
    "            f.write(json.dumps(total_per_clus_str)+'\\n')\n",
    "            \n",
    "            homogeneity_per_clus = cur_run[\"clus_homogeneity_proportion\"]\n",
    "            homogeneity_per_clus_str = {str(k): str(total_per_clus[k]) for k in list(homogeneity_per_clus)}\n",
    "            f.write(\"homogeneity proportion per clus: \\n\\n\")\n",
    "            f.write(json.dumps(homogeneity_per_clus_str)+\"\\n\\n\")\n",
    "            f.write(\"silhouette score: {}\".format(str(cur_run[\"silhouette\"])))\n",
    "            \n",
    "        with open('fulldocclustering/{}ps_clus_cands{}{}.txt'.format(algo,str(ix),acronyms_str),'w',encoding='utf-8') as f:\n",
    "            ps_clus, cands_in_ps_clus = find_acronyms(fulldoc_df, cur_run[\"labels\"],acronyms)\n",
    "            f.write(\"ps cluster label: {}\\n\\n\".format(str(ps_clus)))\n",
    "            for cand in cands_in_ps_clus:\n",
    "                f.write(cand+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>OPTICS clustering</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ground_truths_hash = \n",
    "opt_runs = []\n",
    "opt_min_samples = [5,8,11,14]\n",
    "opt_distances = [\"minkowski\",\"cosine\"]\n",
    "leaf_sizes = [20,25,30,35,40]\n",
    "\n",
    "for min_sample_size in opt_min_samples:\n",
    "    for metric in opt_distances:\n",
    "        for leaf_size in leaf_sizes:\n",
    "            params = {\"min_samples\":min_sample_size,\n",
    "                     \"metric\": metric,\n",
    "                     \"leaf_size\": leaf_size}\n",
    "            labels = run_optics(X,params)\n",
    "            \n",
    "            opt_gt_total, opt_counter = get_cluster_homogeneity(labels,fulldoc_df.candidate,ground_truths_hash)\n",
    "            proportion = get_homogeneity_proportion(opt_gt_total, opt_counter)\n",
    "            opt_runs.append({\"params\":params,\n",
    "                             \"labels\":labels,\n",
    "                             \"total_per_clus\":opt_counter,\n",
    "                             \"clus_homogeneity_proportion\": proportion})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_files(opt_runs,\"optics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Agglomerative Clustering </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "\n",
    "agg_runs = []\n",
    "n_clusters = [2,3,4,5]\n",
    "agg_linkage = [\"ward\",\"complete\",\"average\",\"single\"]\n",
    "\n",
    "for cluster_size in n_clusters:\n",
    "    for linkage in agg_linkage:\n",
    "        params = {\"n_clusters\":cluster_size,\n",
    "                     \"linkage\": linkage}\n",
    "        labels = run_agg_clustering(X,params)\n",
    "            \n",
    "        agg_gt_total, agg_counter = get_cluster_homogeneity(labels,fulldoc_df.candidate,ground_truths_hash)\n",
    "        proportion = get_homogeneity_proportion(agg_gt_total, agg_counter)\n",
    "        agg_runs.append({\"params\":params,\n",
    "                             \"labels\":labels,\n",
    "                             \"total_per_clus\":agg_counter,\n",
    "                             \"clus_homogeneity_proportion\": proportion,\n",
    "                            \"silhouette\":silhouette_score(X,labels)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "write_files(agg_runs,\"agg\",[\"PS\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>KMeans</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_runs = []\n",
    "k_params = [2,4,6,8,10,12]\n",
    "\n",
    "for k in k_params:\n",
    "    params = {\"n_clusters\":k}\n",
    "    labels = run_kmeans(X,params)\n",
    "            \n",
    "    kmeans_gt_total, kmeans_counter = get_cluster_homogeneity(labels,fulldoc_df.candidate,ground_truths_hash)\n",
    "    proportion = get_homogeneity_proportion(kmeans_gt_total, kmeans_counter)\n",
    "    kmeans_runs.append({\"params\":params,\n",
    "                    \"labels\":labels,\n",
    "                    \"total_per_clus\":kmeans_counter,\n",
    "                             \"clus_homogeneity_proportion\": proportion})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_files(kmeans_runs,\"kmeans\",[\"PS\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After exploring each of the clustering output files,\n",
    " it seems agglomerative clustering does the best job of finding \n",
    "    other acronyms inside the cluster with 'PS'. \n",
    "    Next, we will add more common acronyms of https://docs.google.com/document/d/1bg1gcx_V1Ze2mYY3n1GQN2qb4neBKypYgazUreKfa68/edit\n",
    "    \n",
    "Also, silhouette curves will be drawn for Agglomerative clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "agg_runs = []\n",
    "n_clusters = [2,3,4,5]\n",
    "agg_linkage = [\"ward\",\"complete\",\"average\",\"single\"]\n",
    "\n",
    "for cluster_size in n_clusters:\n",
    "    for linkage in agg_linkage:\n",
    "        params = {\"n_clusters\":min_sample_size,\n",
    "                     \"linkage\": linkage}\n",
    "        labels = run_agg_clustering(X,params)\n",
    "            \n",
    "        agg_gt_total, agg_counter = get_cluster_homogeneity(labels,fulldoc_df.candidate,ground_truths_hash)\n",
    "        proportion = get_homogeneity_proportion(agg_gt_total, agg_counter)\n",
    "        agg_data = {\"params\":params,\n",
    "                             \"labels\":labels,\n",
    "                             \"total_per_clus\":agg_counter,\n",
    "                             \"clus_homogeneity_proportion\": proportion,\n",
    "                               \"silhouette\":silhouette_score(X,labels)}\n",
    "        agg_runs.append(agg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_files(agg_runs,\"agg\",[\"PS\",\"PMMA\",\"PEO\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.22091304386615715,\n",
       " 0.22602389231371353,\n",
       " 0.2167509388477557,\n",
       " -0.06200067975859301,\n",
       " 0.22091304386615715,\n",
       " 0.22602389231371353,\n",
       " 0.2167509388477557,\n",
       " -0.06200067975859301,\n",
       " 0.22091304386615715,\n",
       " 0.22602389231371353,\n",
       " 0.2167509388477557,\n",
       " -0.06200067975859301,\n",
       " 0.22091304386615715,\n",
       " 0.22602389231371353,\n",
       " 0.2167509388477557,\n",
       " -0.06200067975859301]"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x['silhouette'] for x in agg_runs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
